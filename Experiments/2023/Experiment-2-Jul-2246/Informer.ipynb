{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(1, \"Informer-Tensorflow/models\")\n",
    "sys.path.insert(1, \"Informer-Tensorflow\")\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attn import ProbAttention, AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadProbAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadProbAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.attn = AttentionLayer(ProbAttention(False), self.d_model, self.num_heads)\n",
    "    def call(self, inputs):\n",
    "        query = inputs\n",
    "        key = inputs\n",
    "        value = inputs\n",
    "        x = self.attn([query, key, value])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    depth = depth/2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "    angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis=-1) \n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        # self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "    # def compute_mask(self, *args, **kwargs):\n",
    "    #     return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        # x = self.embedding(x)\n",
    "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(keras.layers.Layer):\n",
    "    def __init__(self, c_in):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.downConv = tf.keras.layers.Conv1D(\n",
    "                                  filters=c_in,\n",
    "                                  kernel_size=3,\n",
    "                                  padding='causal')\n",
    "        self.norm = tf.keras.layers.BatchNormalization()\n",
    "        self.activation = tf.keras.layers.ELU()\n",
    "        self.maxPool = tf.keras.layers.MaxPool1D(pool_size=3)#, strides=2)\n",
    "\n",
    "    def call(self, x, **kargs):\n",
    "        x = self.downConv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxPool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models():\n",
    "    inputs = keras.layers.Input(shape=(2000,1), batch_size=8)\n",
    "    x = keras.layers.Dense(32, activation=\"tanh\")(inputs)\n",
    "    x = PositionalEmbedding(32)(x)\n",
    "    x = MultiHeadProbAttention(64, 32)(x)\n",
    "    x = ConvLayer(32)(x)\n",
    "    x = keras.layers.LayerNormalization()(x)\n",
    "    x = keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = keras.layers.Dense(5)(x)\n",
    "    return keras.Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([8, 2000, 32]), TensorShape([8, 2000, 32]), TensorShape([8, 2000, 32])]\n"
     ]
    }
   ],
   "source": [
    "model = models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(8, 2000, 1)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (8, 2000, 32)             64        \n",
      "_________________________________________________________________\n",
      "positional_embedding (Positi (8, 2000, 32)             0         \n",
      "_________________________________________________________________\n",
      "multi_head_prob_attention (M (8, 2000, 64)             10496     \n",
      "_________________________________________________________________\n",
      "conv_layer (ConvLayer)       (8, 666, 32)              6304      \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (8, 666, 32)              64        \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (8, 32)                   0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (8, 5)                    165       \n",
      "=================================================================\n",
      "Total params: 17,093\n",
      "Trainable params: 17,029\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 5), dtype=float32, numpy=\n",
       "array([[ 0.92995197, -1.2726281 , -0.37056383, -2.17059   , -0.35434908],\n",
       "       [ 0.92995197, -1.2726281 , -0.37056383, -2.17059   , -0.35434908],\n",
       "       [ 0.92995197, -1.2726281 , -0.37056383, -2.17059   , -0.35434908],\n",
       "       [ 0.92995197, -1.2726281 , -0.37056383, -2.17059   , -0.35434908],\n",
       "       [ 0.92995197, -1.2726281 , -0.37056383, -2.17059   , -0.35434908],\n",
       "       [ 0.92995197, -1.2726281 , -0.37056383, -2.17059   , -0.35434908],\n",
       "       [ 0.92995197, -1.2726281 , -0.37056383, -2.17059   , -0.35434908],\n",
       "       [ 0.92995197, -1.2726281 , -0.37056383, -2.17059   , -0.35434908]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.ones([8,2000,1])\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"data_shuffled.npz\")\n",
    "X = data[\"X\"]\n",
    "Y = data[\"Y\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(32)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer PositionalEmbedding has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/500\n",
      "113/113 [==============================] - 137s 1s/step - loss: 0.4059 - accuracy: 0.8595 - val_loss: 2.5529 - val_accuracy: 0.4896\n",
      "Epoch 2/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.4040 - accuracy: 0.8772 - val_loss: 13.8416 - val_accuracy: 0.2083\n",
      "Epoch 3/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.3946 - accuracy: 0.8717 - val_loss: 2.9818 - val_accuracy: 0.5104\n",
      "Epoch 4/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.4141 - accuracy: 0.8606 - val_loss: 1.8517 - val_accuracy: 0.5417\n",
      "Epoch 5/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.4007 - accuracy: 0.8684 - val_loss: 5.6026 - val_accuracy: 0.4167\n",
      "Epoch 6/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.4017 - accuracy: 0.8595 - val_loss: 3.4229 - val_accuracy: 0.4688\n",
      "Epoch 7/500\n",
      "113/113 [==============================] - 7s 65ms/step - loss: 0.4007 - accuracy: 0.8650 - val_loss: 4.4034 - val_accuracy: 0.4896\n",
      "Epoch 8/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.4111 - accuracy: 0.8551 - val_loss: 1.1237 - val_accuracy: 0.6667\n",
      "Epoch 9/500\n",
      "113/113 [==============================] - 7s 65ms/step - loss: 0.4235 - accuracy: 0.8540 - val_loss: 1.8832 - val_accuracy: 0.5208\n",
      "Epoch 10/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.4026 - accuracy: 0.8551 - val_loss: 2.0154 - val_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.4046 - accuracy: 0.8551 - val_loss: 4.0618 - val_accuracy: 0.4062\n",
      "Epoch 12/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.3900 - accuracy: 0.8695 - val_loss: 1.6667 - val_accuracy: 0.4479\n",
      "Epoch 13/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.3949 - accuracy: 0.8673 - val_loss: 1.2081 - val_accuracy: 0.6458\n",
      "Epoch 14/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.4327 - accuracy: 0.8462 - val_loss: 3.7726 - val_accuracy: 0.4062\n",
      "Epoch 15/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.4014 - accuracy: 0.8617 - val_loss: 2.1289 - val_accuracy: 0.5729\n",
      "Epoch 16/500\n",
      "113/113 [==============================] - 8s 71ms/step - loss: 0.4144 - accuracy: 0.8639 - val_loss: 1.5912 - val_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.3994 - accuracy: 0.8739 - val_loss: 2.0301 - val_accuracy: 0.5104\n",
      "Epoch 18/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.4033 - accuracy: 0.8639 - val_loss: 3.7786 - val_accuracy: 0.3958\n",
      "Epoch 19/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.4036 - accuracy: 0.8673 - val_loss: 4.5643 - val_accuracy: 0.2188\n",
      "Epoch 20/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.3849 - accuracy: 0.8695 - val_loss: 5.8146 - val_accuracy: 0.4062\n",
      "Epoch 21/500\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.3974 - accuracy: 0.8662 - val_loss: 1.0320 - val_accuracy: 0.6146\n",
      "Epoch 22/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.3912 - accuracy: 0.8684 - val_loss: 3.4379 - val_accuracy: 0.4062\n",
      "Epoch 23/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.3885 - accuracy: 0.8783 - val_loss: 2.0898 - val_accuracy: 0.5417\n",
      "Epoch 24/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.4205 - accuracy: 0.8717 - val_loss: 2.2380 - val_accuracy: 0.5521\n",
      "Epoch 25/500\n",
      "113/113 [==============================] - 8s 72ms/step - loss: 0.4172 - accuracy: 0.8639 - val_loss: 3.3302 - val_accuracy: 0.5104\n",
      "Epoch 26/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.3997 - accuracy: 0.8628 - val_loss: 1.0201 - val_accuracy: 0.6667\n",
      "Epoch 27/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3997 - accuracy: 0.8650 - val_loss: 13.6249 - val_accuracy: 0.2083\n",
      "Epoch 28/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3842 - accuracy: 0.8695 - val_loss: 1.1564 - val_accuracy: 0.6562\n",
      "Epoch 29/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.4093 - accuracy: 0.8628 - val_loss: 4.0999 - val_accuracy: 0.5104\n",
      "Epoch 30/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.4028 - accuracy: 0.8639 - val_loss: 2.4249 - val_accuracy: 0.4167\n",
      "Epoch 31/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.4234 - accuracy: 0.8562 - val_loss: 0.9512 - val_accuracy: 0.7083\n",
      "Epoch 32/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.4247 - accuracy: 0.8529 - val_loss: 0.9424 - val_accuracy: 0.6979\n",
      "Epoch 33/500\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.3933 - accuracy: 0.8695 - val_loss: 3.4338 - val_accuracy: 0.4167\n",
      "Epoch 34/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3858 - accuracy: 0.8728 - val_loss: 6.3703 - val_accuracy: 0.2188\n",
      "Epoch 35/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.4000 - accuracy: 0.8662 - val_loss: 3.2870 - val_accuracy: 0.4896\n",
      "Epoch 36/500\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.4082 - accuracy: 0.8573 - val_loss: 2.4138 - val_accuracy: 0.4688\n",
      "Epoch 37/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.4068 - accuracy: 0.8628 - val_loss: 2.8413 - val_accuracy: 0.4167\n",
      "Epoch 38/500\n",
      "113/113 [==============================] - 9s 76ms/step - loss: 0.4005 - accuracy: 0.8684 - val_loss: 3.8361 - val_accuracy: 0.2188\n",
      "Epoch 39/500\n",
      "113/113 [==============================] - 8s 70ms/step - loss: 0.4022 - accuracy: 0.8628 - val_loss: 4.9513 - val_accuracy: 0.4062\n",
      "Epoch 40/500\n",
      "113/113 [==============================] - 8s 68ms/step - loss: 0.4056 - accuracy: 0.8562 - val_loss: 6.6850 - val_accuracy: 0.4688\n",
      "Epoch 41/500\n",
      "113/113 [==============================] - 8s 72ms/step - loss: 0.3942 - accuracy: 0.8573 - val_loss: 0.8307 - val_accuracy: 0.6979\n",
      "Epoch 42/500\n",
      "113/113 [==============================] - 8s 68ms/step - loss: 0.3928 - accuracy: 0.8750 - val_loss: 2.2736 - val_accuracy: 0.5521\n",
      "Epoch 43/500\n",
      "113/113 [==============================] - 7s 66ms/step - loss: 0.4072 - accuracy: 0.8562 - val_loss: 2.1903 - val_accuracy: 0.6042\n",
      "Epoch 44/500\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.4145 - accuracy: 0.8584 - val_loss: 5.2537 - val_accuracy: 0.3333\n",
      "Epoch 45/500\n",
      "113/113 [==============================] - 7s 64ms/step - loss: 0.4136 - accuracy: 0.8639 - val_loss: 2.9323 - val_accuracy: 0.4583\n",
      "Epoch 46/500\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.4026 - accuracy: 0.8650 - val_loss: 4.8436 - val_accuracy: 0.4271\n",
      "Epoch 47/500\n",
      "113/113 [==============================] - 7s 64ms/step - loss: 0.3971 - accuracy: 0.8717 - val_loss: 2.0845 - val_accuracy: 0.4167\n",
      "Epoch 48/500\n",
      "113/113 [==============================] - 7s 65ms/step - loss: 0.3907 - accuracy: 0.8650 - val_loss: 4.0989 - val_accuracy: 0.4062\n",
      "Epoch 49/500\n",
      "113/113 [==============================] - 9s 77ms/step - loss: 0.3895 - accuracy: 0.8684 - val_loss: 0.8712 - val_accuracy: 0.6979\n",
      "Epoch 50/500\n",
      "113/113 [==============================] - 9s 74ms/step - loss: 0.4043 - accuracy: 0.8684 - val_loss: 1.9504 - val_accuracy: 0.5521\n",
      "Epoch 51/500\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.3909 - accuracy: 0.8662 - val_loss: 1.4117 - val_accuracy: 0.5833\n",
      "Epoch 52/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.3891 - accuracy: 0.8628 - val_loss: 4.9311 - val_accuracy: 0.4479\n",
      "Epoch 53/500\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.3763 - accuracy: 0.8695 - val_loss: 13.1697 - val_accuracy: 0.2083\n",
      "Epoch 54/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.4114 - accuracy: 0.8628 - val_loss: 1.2039 - val_accuracy: 0.6562\n",
      "Epoch 55/500\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.3854 - accuracy: 0.8684 - val_loss: 4.8118 - val_accuracy: 0.4479\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 7s 63ms/step - loss: 0.3902 - accuracy: 0.8761 - val_loss: 6.8153 - val_accuracy: 0.2188\n",
      "Epoch 57/500\n",
      "113/113 [==============================] - 9s 77ms/step - loss: 0.3870 - accuracy: 0.8717 - val_loss: 1.6397 - val_accuracy: 0.5938\n",
      "Epoch 58/500\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.3942 - accuracy: 0.8662 - val_loss: 4.3270 - val_accuracy: 0.4375\n",
      "Epoch 59/500\n",
      "113/113 [==============================] - 7s 64ms/step - loss: 0.3966 - accuracy: 0.8673 - val_loss: 2.8714 - val_accuracy: 0.2604\n",
      "Epoch 60/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.4033 - accuracy: 0.8606 - val_loss: 6.1249 - val_accuracy: 0.2500\n",
      "Epoch 61/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.4035 - accuracy: 0.8662 - val_loss: 3.2466 - val_accuracy: 0.5312\n",
      "Epoch 62/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.4070 - accuracy: 0.8684 - val_loss: 0.8848 - val_accuracy: 0.7188\n",
      "Epoch 63/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.4064 - accuracy: 0.8518 - val_loss: 4.2358 - val_accuracy: 0.4062\n",
      "Epoch 64/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.4063 - accuracy: 0.8595 - val_loss: 1.6161 - val_accuracy: 0.5208\n",
      "Epoch 65/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.3967 - accuracy: 0.8662 - val_loss: 2.9367 - val_accuracy: 0.5208\n",
      "Epoch 66/500\n",
      "113/113 [==============================] - 8s 71ms/step - loss: 0.4138 - accuracy: 0.8639 - val_loss: 1.7159 - val_accuracy: 0.5417\n",
      "Epoch 67/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.3951 - accuracy: 0.8706 - val_loss: 3.0762 - val_accuracy: 0.4688\n",
      "Epoch 68/500\n",
      "113/113 [==============================] - 7s 65ms/step - loss: 0.3858 - accuracy: 0.8772 - val_loss: 1.3634 - val_accuracy: 0.6042\n",
      "Epoch 69/500\n",
      "113/113 [==============================] - 8s 72ms/step - loss: 0.3874 - accuracy: 0.8706 - val_loss: 1.9495 - val_accuracy: 0.6146\n",
      "Epoch 70/500\n",
      "113/113 [==============================] - 8s 72ms/step - loss: 0.4007 - accuracy: 0.8573 - val_loss: 3.0797 - val_accuracy: 0.3750\n",
      "Epoch 71/500\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.3905 - accuracy: 0.8684 - val_loss: 1.1684 - val_accuracy: 0.6250\n",
      "Epoch 72/500\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.3851 - accuracy: 0.8662 - val_loss: 1.0493 - val_accuracy: 0.5938\n",
      "Epoch 73/500\n",
      "113/113 [==============================] - 7s 64ms/step - loss: 0.3855 - accuracy: 0.8650 - val_loss: 2.4870 - val_accuracy: 0.4583\n",
      "Epoch 74/500\n",
      "113/113 [==============================] - 9s 83ms/step - loss: 0.4024 - accuracy: 0.8662 - val_loss: 1.6850 - val_accuracy: 0.6042\n",
      "Epoch 75/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.3906 - accuracy: 0.8650 - val_loss: 3.2791 - val_accuracy: 0.3229\n",
      "Epoch 76/500\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.4107 - accuracy: 0.8650 - val_loss: 2.7280 - val_accuracy: 0.5208\n",
      "Epoch 77/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.3732 - accuracy: 0.8761 - val_loss: 3.4465 - val_accuracy: 0.3750\n",
      "Epoch 78/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3923 - accuracy: 0.8706 - val_loss: 4.6074 - val_accuracy: 0.3125\n",
      "Epoch 79/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3874 - accuracy: 0.8662 - val_loss: 2.3570 - val_accuracy: 0.4479\n",
      "Epoch 80/500\n",
      "113/113 [==============================] - 7s 66ms/step - loss: 0.3991 - accuracy: 0.8684 - val_loss: 1.7136 - val_accuracy: 0.5729\n",
      "Epoch 81/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3781 - accuracy: 0.8772 - val_loss: 1.7970 - val_accuracy: 0.5000\n",
      "Epoch 82/500\n",
      "113/113 [==============================] - 8s 71ms/step - loss: 0.4317 - accuracy: 0.8540 - val_loss: 3.3497 - val_accuracy: 0.5104\n",
      "Epoch 83/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.3970 - accuracy: 0.8595 - val_loss: 1.5273 - val_accuracy: 0.5833\n",
      "Epoch 84/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3946 - accuracy: 0.8717 - val_loss: 3.5829 - val_accuracy: 0.2708\n",
      "Epoch 85/500\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.4033 - accuracy: 0.8684 - val_loss: 1.8805 - val_accuracy: 0.5208\n",
      "Epoch 86/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.3888 - accuracy: 0.8617 - val_loss: 4.1551 - val_accuracy: 0.2292\n",
      "Epoch 87/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.3870 - accuracy: 0.8684 - val_loss: 0.8858 - val_accuracy: 0.7188\n",
      "Epoch 88/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.4000 - accuracy: 0.8662 - val_loss: 1.5911 - val_accuracy: 0.5208\n",
      "Epoch 89/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.3896 - accuracy: 0.8695 - val_loss: 0.7007 - val_accuracy: 0.7604\n",
      "Epoch 90/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.3878 - accuracy: 0.8717 - val_loss: 4.5307 - val_accuracy: 0.3229\n",
      "Epoch 91/500\n",
      "113/113 [==============================] - 7s 66ms/step - loss: 0.3820 - accuracy: 0.8750 - val_loss: 1.1536 - val_accuracy: 0.6771\n",
      "Epoch 92/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.3883 - accuracy: 0.8639 - val_loss: 1.0583 - val_accuracy: 0.6458\n",
      "Epoch 93/500\n",
      "113/113 [==============================] - 7s 64ms/step - loss: 0.3923 - accuracy: 0.8706 - val_loss: 1.2472 - val_accuracy: 0.5833\n",
      "Epoch 94/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3720 - accuracy: 0.8739 - val_loss: 3.9574 - val_accuracy: 0.2917\n",
      "Epoch 95/500\n",
      "113/113 [==============================] - 7s 64ms/step - loss: 0.3835 - accuracy: 0.8794 - val_loss: 3.1085 - val_accuracy: 0.4792\n",
      "Epoch 96/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.3956 - accuracy: 0.8662 - val_loss: 1.8992 - val_accuracy: 0.6146\n",
      "Epoch 97/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.4048 - accuracy: 0.8639 - val_loss: 1.6007 - val_accuracy: 0.6562\n",
      "Epoch 98/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3792 - accuracy: 0.8783 - val_loss: 1.5196 - val_accuracy: 0.6562\n",
      "Epoch 99/500\n",
      "113/113 [==============================] - 8s 70ms/step - loss: 0.3888 - accuracy: 0.8695 - val_loss: 2.3326 - val_accuracy: 0.5312\n",
      "Epoch 100/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3786 - accuracy: 0.8827 - val_loss: 9.9015 - val_accuracy: 0.2188\n",
      "Epoch 101/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.3899 - accuracy: 0.8684 - val_loss: 3.9657 - val_accuracy: 0.4167\n",
      "Epoch 102/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.3812 - accuracy: 0.8761 - val_loss: 2.5732 - val_accuracy: 0.4896\n",
      "Epoch 103/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3939 - accuracy: 0.8673 - val_loss: 2.6520 - val_accuracy: 0.2500\n",
      "Epoch 104/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.3799 - accuracy: 0.8772 - val_loss: 5.5116 - val_accuracy: 0.2917\n",
      "Epoch 105/500\n",
      "113/113 [==============================] - 7s 59ms/step - loss: 0.3739 - accuracy: 0.8650 - val_loss: 3.9333 - val_accuracy: 0.4583\n",
      "Epoch 106/500\n",
      "113/113 [==============================] - 7s 58ms/step - loss: 0.3831 - accuracy: 0.8695 - val_loss: 1.2384 - val_accuracy: 0.6146\n",
      "Epoch 107/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3850 - accuracy: 0.8639 - val_loss: 2.4333 - val_accuracy: 0.4688\n",
      "Epoch 108/500\n",
      "113/113 [==============================] - 9s 80ms/step - loss: 0.3754 - accuracy: 0.8783 - val_loss: 2.2875 - val_accuracy: 0.4896\n",
      "Epoch 109/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3735 - accuracy: 0.8739 - val_loss: 4.0896 - val_accuracy: 0.4792\n",
      "Epoch 110/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3758 - accuracy: 0.8695 - val_loss: 3.5763 - val_accuracy: 0.3333\n",
      "Epoch 111/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3960 - accuracy: 0.8673 - val_loss: 1.2076 - val_accuracy: 0.6458\n",
      "Epoch 112/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3778 - accuracy: 0.8750 - val_loss: 6.1609 - val_accuracy: 0.1979\n",
      "Epoch 113/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.3987 - accuracy: 0.8551 - val_loss: 2.2957 - val_accuracy: 0.4271\n",
      "Epoch 114/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3791 - accuracy: 0.8662 - val_loss: 4.1937 - val_accuracy: 0.4896\n",
      "Epoch 115/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.3756 - accuracy: 0.8772 - val_loss: 1.2549 - val_accuracy: 0.5521\n",
      "Epoch 116/500\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.3807 - accuracy: 0.8628 - val_loss: 6.4978 - val_accuracy: 0.4896\n",
      "Epoch 117/500\n",
      "113/113 [==============================] - 9s 64ms/step - loss: 0.3724 - accuracy: 0.8805 - val_loss: 1.1148 - val_accuracy: 0.6979\n",
      "Epoch 118/500\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.4000 - accuracy: 0.8684 - val_loss: 1.4490 - val_accuracy: 0.5417\n",
      "Epoch 119/500\n",
      " 15/113 [==>...........................] - ETA: 5s - loss: 0.3677 - accuracy: 0.8917"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d4c1006ce385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(x=X[0:904], y=Y[0:904], batch_size=8, epochs=500, validation_data=(X[904:], Y[904:]),\n\u001b[0m\u001b[1;32m      2\u001b[0m          callbacks=[tensorboard_callback])\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=X[0:904], y=Y[0:904], batch_size=8, epochs=500, validation_data=(X[904:], Y[904:]),\n",
    "         callbacks=[tensorboard_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

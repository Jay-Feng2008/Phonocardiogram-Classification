{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1704197511430,
     "user": {
      "displayName": "Jay Feng",
      "userId": "05408265157775379755"
     },
     "user_tz": -480
    },
    "id": "I3co8joE-DHn",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 23:23:46.296706: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-06 23:23:47.048309: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from layers import PositionalEmbedding, MultiHeadSelfAttention, ConvLayer\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pCM3E_vF826"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1704197513382,
     "user": {
      "displayName": "Jay Feng",
      "userId": "05408265157775379755"
     },
     "user_tz": -480
    },
    "id": "GbSF1ZRNCCkw"
   },
   "outputs": [],
   "source": [
    "f = np.load(\"mfcc_fixed.npz\")\n",
    "X, Y = f['X'], f['Y']\n",
    "fold = 10\n",
    "X_train =  np.concatenate((X[0:(fold-1)*100], X[fold*100:1000]))\n",
    "Y_train =  np.concatenate((Y[0:(fold-1)*100], Y[fold*100:1000]))\n",
    "\n",
    "\n",
    "x_test, y_test = X[(fold-1)*100:fold*100], Y[(fold-1)*100:fold*100]\n",
    "x_train, y_train = X_train[0:800], Y_train[0:800]\n",
    "x_val, y_val= X_train[800:900], Y_train[800:900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "executionInfo": {
     "elapsed": 559,
     "status": "ok",
     "timestamp": 1704197513939,
     "user": {
      "displayName": "Jay Feng",
      "userId": "05408265157775379755"
     },
     "user_tz": -480
    },
    "id": "sacNlUalBHKm"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=800, reshuffle_each_iteration=True).batch(batch_size, drop_remainder=True)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size, drop_remainder=True)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "\n",
    "x = x_train[0:batch_size]\n",
    "x_rank = tf.rank(x).numpy()\n",
    "x_norm_resize_shape = [batch_size] + list(tf.ones(tf.rank(x), dtype=tf.int32).numpy())[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WTahBhXELN1"
   },
   "source": [
    "# Build Trainable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1704197514506,
     "user": {
      "displayName": "Jay Feng",
      "userId": "05408265157775379755"
     },
     "user_tz": -480
    },
    "id": "jy6oND-DHHcq"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "kl_divergence = keras.losses.KLDivergence()\n",
    "lds = lambda x, y: tf.math.reduce_sum(keras.losses.kl_divergence(x, y))\n",
    "acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "zeta = 1e-6\n",
    "eps = 4.0\n",
    "alpha = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1704197515192,
     "user": {
      "displayName": "Jay Feng",
      "userId": "05408265157775379755"
     },
     "user_tz": -480
    },
    "id": "P6GFTn1UEPBC"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "\n",
    "        x_p = tf.random.normal(x.shape)\n",
    "        x_norm = x_p\n",
    "        for i in range(x_rank-1, 0, -1):\n",
    "            x_norm = tf.norm(x_norm, ord=2, axis=int(i))\n",
    "        x_p /= tf.reshape(x_norm, (batch_size, 1, 1))\n",
    "        x_p *= zeta\n",
    "\n",
    "        with tf.GradientTape() as adversarial_tape:\n",
    "            adversarial_tape.watch(x_p)\n",
    "            y_p = model(x + x_p, training=True)\n",
    "            logits = self(x, training=True)\n",
    "            l = lds(logits, y_p)\n",
    "        g = adversarial_tape.gradient(l, x_p)\n",
    "\n",
    "        g_norm = g\n",
    "        for i in range(x_rank-1, 0, -1):\n",
    "            g_norm = tf.norm(g_norm, ord=2, axis=int(i))\n",
    "\n",
    "        x_p = eps * g / (tf.reshape(g_norm, x_norm_resize_shape)+1e-6)\n",
    "\n",
    "        with tf.GradientTape() as model_tape:\n",
    "            y_p = self(x + x_p, training=True)\n",
    "            logits = self(x, training=True)\n",
    "            l = lds(logits, y_p)    # Recalculate regularization\n",
    "            loss = self.compute_loss(y=y, y_pred=logits) + alpha * l / batch_size\n",
    "        grads = model_tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        for metric in self.metrics:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "                metric.update_state(y, logits)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# model = CustomModel(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(d_model_init=64, num_heads=[2, 2], classes=5, input_shape=(137, 15), batch_size=batch_size):\n",
    "    inputs = keras.layers.Input(shape=input_shape, batch_size=batch_size)\n",
    "    x = PositionalEmbedding(d_model=d_model_init)(inputs)\n",
    "#     for n_heads in num_heads:\n",
    "#         x = MultiHeadSelfAttention(d_model=d_model, num_heads=n_heads)(x)\n",
    "#         x = ConvLayer(d_model)(x)\n",
    "    x = MultiHeadSelfAttention(d_model=d_model_init, num_heads=num_heads[0])(x)\n",
    "    x = ConvLayer(d_model_init)(x)\n",
    "    x = tf.keras.layers.Permute((2, 1))(x)\n",
    "    x = PositionalEmbedding(d_model=d_model_init)(x)\n",
    "    x = MultiHeadSelfAttention(d_model=d_model_init, num_heads=num_heads[0])(x)\n",
    "    x = ConvLayer(d_model_init)(x)\n",
    "    x = keras.layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    x = keras.layers.Dense(classes, activation='softmax')(x)\n",
    "    return CustomModel(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1704197515930,
     "user": {
      "displayName": "Jay Feng",
      "userId": "05408265157775379755"
     },
     "user_tz": -480
    },
    "id": "Z_ablm4illgi"
   },
   "outputs": [],
   "source": [
    "model = build_model(input_shape = X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1704197516352,
     "user": {
      "displayName": "Jay Feng",
      "userId": "05408265157775379755"
     },
     "user_tz": -480
    },
    "id": "uHejJUqrxcGT",
    "outputId": "602d1f20-68f4-4a1a-ce41-ff169b1d2f49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(32, 54, 30)]            0         \n",
      "                                                                 \n",
      " positional_embedding_18 (Po  (32, 54, 64)             1984      \n",
      " sitionalEmbedding)                                              \n",
      "                                                                 \n",
      " multi_head_self_attention_1  (32, 54, 64)             33344     \n",
      " 8 (MultiHeadSelfAttention)                                      \n",
      "                                                                 \n",
      " conv_layer_18 (ConvLayer)   (32, 54, 64)              65856     \n",
      "                                                                 \n",
      " permute_9 (Permute)         (32, 64, 54)              0         \n",
      "                                                                 \n",
      " positional_embedding_19 (Po  (32, 64, 64)             3520      \n",
      " sitionalEmbedding)                                              \n",
      "                                                                 \n",
      " multi_head_self_attention_1  (32, 64, 64)             33344     \n",
      " 9 (MultiHeadSelfAttention)                                      \n",
      "                                                                 \n",
      " conv_layer_19 (ConvLayer)   (32, 64, 64)              65856     \n",
      "                                                                 \n",
      " global_average_pooling1d_9   (32, 64)                 0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_89 (Dense)            (32, 5)                   325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 204,229\n",
      "Trainable params: 204,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1704197517964,
     "user": {
      "displayName": "Jay Feng",
      "userId": "05408265157775379755"
     },
     "user_tz": -480
    },
    "id": "0soe1b7rJDqZ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])\n",
    "mcp_callback = keras.callbacks.ModelCheckpoint(\"checkpoint.weights.h5\",\n",
    "                                                monitor=\"val_loss\",\n",
    "                                                verbose=1,\n",
    "                                                save_best_only=True,\n",
    "                                                save_weights_only=True,)\n",
    "es_callback = keras.callbacks.EarlyStopping(\n",
    "                                            monitor=\"val_loss\",\n",
    "                                            min_delta=0,\n",
    "                                            patience=100,\n",
    "                                            verbose=1,\n",
    "                                            mode=\"auto\",\n",
    "                                            baseline=None,\n",
    "                                            restore_best_weights=True,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5002082,
     "status": "error",
     "timestamp": 1704202520641,
     "user": {
      "displayName": "Jay Feng",
      "userId": "05408265157775379755"
     },
     "user_tz": -480
    },
    "id": "D3pNSWR6JPWm",
    "outputId": "a61af009-0d77-476f-fe23-0a60ec8620a7",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 01:06:51.372890: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [800]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-07-07 01:06:51.373318: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [800]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/25 [===========================>..] - ETA: 0s - loss: 1.6085"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 01:07:16.186085: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [100]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 27s 132ms/step - loss: 1.6083 - val_loss: 1.6028 - val_accuracy: 0.4375\n",
      "Epoch 2/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 1.5866 - val_loss: 1.5468 - val_accuracy: 0.5312\n",
      "Epoch 3/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 1.4942 - val_loss: 1.4121 - val_accuracy: 0.6146\n",
      "Epoch 4/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 1.3086 - val_loss: 1.1796 - val_accuracy: 0.7708\n",
      "Epoch 5/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 1.1169 - val_loss: 1.0171 - val_accuracy: 0.7604\n",
      "Epoch 6/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.9289 - val_loss: 0.8400 - val_accuracy: 0.7500\n",
      "Epoch 7/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.7984 - val_loss: 0.7452 - val_accuracy: 0.7396\n",
      "Epoch 8/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.8358 - val_loss: 0.8405 - val_accuracy: 0.8125\n",
      "Epoch 9/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.7641 - val_loss: 0.8131 - val_accuracy: 0.7708\n",
      "Epoch 10/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.6953 - val_loss: 0.5906 - val_accuracy: 0.8438\n",
      "Epoch 11/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.6288 - val_loss: 0.5757 - val_accuracy: 0.8125\n",
      "Epoch 12/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.5728 - val_loss: 0.5744 - val_accuracy: 0.8333\n",
      "Epoch 13/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.6069 - val_loss: 0.5941 - val_accuracy: 0.8021\n",
      "Epoch 14/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.5736 - val_loss: 0.5805 - val_accuracy: 0.8229\n",
      "Epoch 15/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.5637 - val_loss: 0.5240 - val_accuracy: 0.8438\n",
      "Epoch 16/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.4811 - val_loss: 0.4282 - val_accuracy: 0.9062\n",
      "Epoch 17/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.4756 - val_loss: 0.5077 - val_accuracy: 0.8750\n",
      "Epoch 18/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.4764 - val_loss: 0.3956 - val_accuracy: 0.8750\n",
      "Epoch 19/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.4753 - val_loss: 0.3891 - val_accuracy: 0.8958\n",
      "Epoch 20/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.3858 - val_loss: 0.3076 - val_accuracy: 0.8958\n",
      "Epoch 21/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.3486 - val_loss: 0.3150 - val_accuracy: 0.8958\n",
      "Epoch 22/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.3913 - val_loss: 0.3585 - val_accuracy: 0.8854\n",
      "Epoch 23/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.3040 - val_loss: 0.2971 - val_accuracy: 0.8958\n",
      "Epoch 24/2000\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 0.2895 - val_loss: 0.2639 - val_accuracy: 0.9271\n",
      "Epoch 25/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2568 - val_loss: 0.2529 - val_accuracy: 0.9167\n",
      "Epoch 26/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2429 - val_loss: 0.2271 - val_accuracy: 0.9062\n",
      "Epoch 27/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.2650 - val_loss: 0.3458 - val_accuracy: 0.8750\n",
      "Epoch 28/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.3898 - val_loss: 0.3214 - val_accuracy: 0.8854\n",
      "Epoch 29/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.3337 - val_loss: 0.2436 - val_accuracy: 0.9062\n",
      "Epoch 30/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2900 - val_loss: 0.2236 - val_accuracy: 0.9062\n",
      "Epoch 31/2000\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2609 - val_loss: 0.1877 - val_accuracy: 0.9479\n",
      "Epoch 32/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.2348 - val_loss: 0.2122 - val_accuracy: 0.8958\n",
      "Epoch 33/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.2358 - val_loss: 0.2361 - val_accuracy: 0.9167\n",
      "Epoch 34/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.2312 - val_loss: 0.2783 - val_accuracy: 0.9167\n",
      "Epoch 35/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.1864 - val_loss: 0.2096 - val_accuracy: 0.9062\n",
      "Epoch 36/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1543 - val_loss: 0.1698 - val_accuracy: 0.9271\n",
      "Epoch 37/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.3298 - val_loss: 0.3836 - val_accuracy: 0.8542\n",
      "Epoch 38/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.4975 - val_loss: 0.4092 - val_accuracy: 0.8854\n",
      "Epoch 39/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.4307 - val_loss: 0.3607 - val_accuracy: 0.8958\n",
      "Epoch 40/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.3977 - val_loss: 0.3114 - val_accuracy: 0.8646\n",
      "Epoch 41/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.3470 - val_loss: 0.2492 - val_accuracy: 0.9271\n",
      "Epoch 42/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.3169 - val_loss: 0.2830 - val_accuracy: 0.8958\n",
      "Epoch 43/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.2836 - val_loss: 0.2520 - val_accuracy: 0.8854\n",
      "Epoch 44/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.2891 - val_loss: 0.2293 - val_accuracy: 0.9271\n",
      "Epoch 45/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2386 - val_loss: 0.2660 - val_accuracy: 0.9167\n",
      "Epoch 46/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.2061 - val_loss: 0.1525 - val_accuracy: 0.9271\n",
      "Epoch 47/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1893 - val_loss: 0.3656 - val_accuracy: 0.8542\n",
      "Epoch 48/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.2610 - val_loss: 0.2240 - val_accuracy: 0.9167\n",
      "Epoch 49/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.2064 - val_loss: 0.2043 - val_accuracy: 0.9479\n",
      "Epoch 50/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.2369 - val_loss: 0.2645 - val_accuracy: 0.8750\n",
      "Epoch 51/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2644 - val_loss: 0.2469 - val_accuracy: 0.9167\n",
      "Epoch 52/2000\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2352 - val_loss: 0.1848 - val_accuracy: 0.9583\n",
      "Epoch 53/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.2564 - val_loss: 0.3189 - val_accuracy: 0.8750\n",
      "Epoch 54/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.2152 - val_loss: 0.1906 - val_accuracy: 0.9479\n",
      "Epoch 55/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.1841 - val_loss: 0.2247 - val_accuracy: 0.9062\n",
      "Epoch 56/2000\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.1467 - val_loss: 0.1451 - val_accuracy: 0.9271\n",
      "Epoch 57/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1593 - val_loss: 0.2097 - val_accuracy: 0.9271\n",
      "Epoch 58/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.1382 - val_loss: 0.1954 - val_accuracy: 0.9167\n",
      "Epoch 59/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1546 - val_loss: 0.1762 - val_accuracy: 0.9271\n",
      "Epoch 60/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.1512 - val_loss: 0.1468 - val_accuracy: 0.9583\n",
      "Epoch 61/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1138 - val_loss: 0.1375 - val_accuracy: 0.9479\n",
      "Epoch 62/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.1065 - val_loss: 0.1387 - val_accuracy: 0.9583\n",
      "Epoch 63/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1426 - val_loss: 0.1152 - val_accuracy: 0.9688\n",
      "Epoch 64/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.1440 - val_loss: 0.1292 - val_accuracy: 0.9375\n",
      "Epoch 65/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.1153 - val_loss: 0.3250 - val_accuracy: 0.8958\n",
      "Epoch 66/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.1874 - val_loss: 0.1500 - val_accuracy: 0.9583\n",
      "Epoch 67/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1586 - val_loss: 0.2044 - val_accuracy: 0.9167\n",
      "Epoch 68/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.1374 - val_loss: 0.1450 - val_accuracy: 0.9479\n",
      "Epoch 69/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0928 - val_loss: 0.1467 - val_accuracy: 0.9375\n",
      "Epoch 70/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.1613 - val_loss: 0.6381 - val_accuracy: 0.7812\n",
      "Epoch 71/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.5684 - val_loss: 0.4517 - val_accuracy: 0.8542\n",
      "Epoch 72/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.3572 - val_loss: 0.3483 - val_accuracy: 0.8958\n",
      "Epoch 73/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.2510 - val_loss: 0.2622 - val_accuracy: 0.8854\n",
      "Epoch 74/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.2018 - val_loss: 0.2321 - val_accuracy: 0.9167\n",
      "Epoch 75/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.1714 - val_loss: 0.2802 - val_accuracy: 0.8958\n",
      "Epoch 76/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1789 - val_loss: 0.1854 - val_accuracy: 0.9375\n",
      "Epoch 77/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.1617 - val_loss: 0.1973 - val_accuracy: 0.9375\n",
      "Epoch 78/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.1785 - val_loss: 0.2652 - val_accuracy: 0.9375\n",
      "Epoch 79/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.1491 - val_loss: 0.2049 - val_accuracy: 0.9167\n",
      "Epoch 80/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1333 - val_loss: 0.1721 - val_accuracy: 0.9583\n",
      "Epoch 81/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.1148 - val_loss: 0.3759 - val_accuracy: 0.8646\n",
      "Epoch 82/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.2131 - val_loss: 0.4149 - val_accuracy: 0.8646\n",
      "Epoch 83/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.2217 - val_loss: 0.1883 - val_accuracy: 0.9479\n",
      "Epoch 84/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.1382 - val_loss: 0.1592 - val_accuracy: 0.9583\n",
      "Epoch 85/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1346 - val_loss: 0.1293 - val_accuracy: 0.9583\n",
      "Epoch 86/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1039 - val_loss: 0.1394 - val_accuracy: 0.9583\n",
      "Epoch 87/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.1141 - val_loss: 0.1000 - val_accuracy: 0.9688\n",
      "Epoch 88/2000\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.1103 - val_loss: 0.0984 - val_accuracy: 0.9688\n",
      "Epoch 89/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.0886 - val_loss: 0.0985 - val_accuracy: 0.9479\n",
      "Epoch 90/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0878 - val_loss: 0.0897 - val_accuracy: 0.9792\n",
      "Epoch 91/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0605 - val_loss: 0.0638 - val_accuracy: 0.9792\n",
      "Epoch 92/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0963 - val_loss: 0.1516 - val_accuracy: 0.9375\n",
      "Epoch 93/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0881 - val_loss: 0.0842 - val_accuracy: 0.9688\n",
      "Epoch 94/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0898 - val_loss: 0.1100 - val_accuracy: 0.9792\n",
      "Epoch 95/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0701 - val_loss: 0.0926 - val_accuracy: 0.9792\n",
      "Epoch 96/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0657 - val_loss: 0.0539 - val_accuracy: 0.9792\n",
      "Epoch 97/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0728 - val_loss: 0.1134 - val_accuracy: 0.9792\n",
      "Epoch 98/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.1066 - val_loss: 0.1126 - val_accuracy: 0.9688\n",
      "Epoch 99/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.0791 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "Epoch 100/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0794 - val_loss: 0.0817 - val_accuracy: 0.9688\n",
      "Epoch 101/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0729 - val_loss: 0.0760 - val_accuracy: 0.9688\n",
      "Epoch 102/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0439 - val_loss: 0.0892 - val_accuracy: 0.9688\n",
      "Epoch 103/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0689 - val_loss: 0.2144 - val_accuracy: 0.9375\n",
      "Epoch 104/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1520 - val_loss: 0.1507 - val_accuracy: 0.9583\n",
      "Epoch 105/2000\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.0577 - val_loss: 0.1307 - val_accuracy: 0.9688\n",
      "Epoch 106/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1062 - val_loss: 0.1936 - val_accuracy: 0.9375\n",
      "Epoch 107/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.0542 - val_loss: 0.0822 - val_accuracy: 0.9688\n",
      "Epoch 108/2000\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.0722 - val_loss: 0.0599 - val_accuracy: 0.9688\n",
      "Epoch 109/2000\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 0.0786 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 110/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0421 - val_loss: 0.1096 - val_accuracy: 0.9688\n",
      "Epoch 111/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0694 - val_loss: 0.1179 - val_accuracy: 0.9583\n",
      "Epoch 112/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0298 - val_loss: 0.0526 - val_accuracy: 0.9896\n",
      "Epoch 113/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0285 - val_loss: 0.0842 - val_accuracy: 0.9792\n",
      "Epoch 114/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.0237 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 115/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0160 - val_loss: 0.0392 - val_accuracy: 0.9792\n",
      "Epoch 116/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0294 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 117/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0322 - val_loss: 0.0313 - val_accuracy: 0.9896\n",
      "Epoch 118/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0401 - val_loss: 0.0627 - val_accuracy: 0.9896\n",
      "Epoch 119/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.0297 - val_loss: 0.0181 - val_accuracy: 0.9896\n",
      "Epoch 120/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.0298 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 121/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1173 - val_loss: 0.1552 - val_accuracy: 0.9479\n",
      "Epoch 122/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0292 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 123/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0164 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 124/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0098 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 125/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0072 - val_loss: 0.0142 - val_accuracy: 0.9896\n",
      "Epoch 126/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0071 - val_loss: 0.0188 - val_accuracy: 0.9896\n",
      "Epoch 127/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0658 - val_loss: 0.0917 - val_accuracy: 0.9688\n",
      "Epoch 128/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0580 - val_loss: 0.0377 - val_accuracy: 0.9792\n",
      "Epoch 129/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0224 - val_loss: 0.0439 - val_accuracy: 0.9896\n",
      "Epoch 130/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.0298 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 131/2000\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.0234 - val_loss: 0.0304 - val_accuracy: 0.9896\n",
      "Epoch 132/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0211 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 133/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0126 - val_loss: 0.0146 - val_accuracy: 0.9896\n",
      "Epoch 134/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0060 - val_loss: 0.0200 - val_accuracy: 0.9896\n",
      "Epoch 135/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0087 - val_loss: 0.0385 - val_accuracy: 0.9896\n",
      "Epoch 136/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.0077 - val_loss: 0.0182 - val_accuracy: 0.9896\n",
      "Epoch 137/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.0035 - val_loss: 0.0239 - val_accuracy: 0.9896\n",
      "Epoch 138/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0031 - val_loss: 0.0348 - val_accuracy: 0.9896\n",
      "Epoch 139/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0029 - val_loss: 0.0215 - val_accuracy: 0.9896\n",
      "Epoch 140/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0027 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 141/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0024 - val_loss: 0.0348 - val_accuracy: 0.9896\n",
      "Epoch 142/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.0080 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 143/2000\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.0029 - val_loss: 0.0248 - val_accuracy: 0.9896\n",
      "Epoch 144/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0021 - val_loss: 0.0249 - val_accuracy: 0.9896\n",
      "Epoch 145/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0020 - val_loss: 0.0222 - val_accuracy: 0.9896\n",
      "Epoch 146/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0018 - val_loss: 0.0255 - val_accuracy: 0.9896\n",
      "Epoch 147/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0018 - val_loss: 0.0253 - val_accuracy: 0.9896\n",
      "Epoch 148/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0033 - val_loss: 0.0564 - val_accuracy: 0.9896\n",
      "Epoch 149/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0798 - val_loss: 0.6048 - val_accuracy: 0.8646\n",
      "Epoch 150/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.2914 - val_loss: 0.1991 - val_accuracy: 0.9375\n",
      "Epoch 151/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.1327 - val_loss: 0.0771 - val_accuracy: 0.9792\n",
      "Epoch 152/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0382 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 153/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0233 - val_loss: 0.0582 - val_accuracy: 0.9583\n",
      "Epoch 154/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0205 - val_loss: 0.0166 - val_accuracy: 0.9896\n",
      "Epoch 155/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0105 - val_loss: 0.0347 - val_accuracy: 0.9688\n",
      "Epoch 156/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0212 - val_loss: 0.1210 - val_accuracy: 0.9792\n",
      "Epoch 157/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.0992 - val_loss: 0.0464 - val_accuracy: 0.9896\n",
      "Epoch 158/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0474 - val_loss: 0.0527 - val_accuracy: 0.9792\n",
      "Epoch 159/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0213 - val_loss: 0.0363 - val_accuracy: 0.9792\n",
      "Epoch 160/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0128 - val_loss: 0.0274 - val_accuracy: 0.9896\n",
      "Epoch 161/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0065 - val_loss: 0.0331 - val_accuracy: 0.9896\n",
      "Epoch 162/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0048 - val_loss: 0.0393 - val_accuracy: 0.9896\n",
      "Epoch 163/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.0037 - val_loss: 0.0462 - val_accuracy: 0.9896\n",
      "Epoch 164/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.0038 - val_loss: 0.0238 - val_accuracy: 0.9896\n",
      "Epoch 165/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0033 - val_loss: 0.0429 - val_accuracy: 0.9896\n",
      "Epoch 166/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0044 - val_loss: 0.0223 - val_accuracy: 0.9896\n",
      "Epoch 167/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0022 - val_loss: 0.0260 - val_accuracy: 0.9896\n",
      "Epoch 168/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0020 - val_loss: 0.0246 - val_accuracy: 0.9896\n",
      "Epoch 169/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0018 - val_loss: 0.0336 - val_accuracy: 0.9896\n",
      "Epoch 170/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0017 - val_loss: 0.0428 - val_accuracy: 0.9896\n",
      "Epoch 171/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0015 - val_loss: 0.0439 - val_accuracy: 0.9896\n",
      "Epoch 172/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0014 - val_loss: 0.0439 - val_accuracy: 0.9896\n",
      "Epoch 173/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0014 - val_loss: 0.0429 - val_accuracy: 0.9896\n",
      "Epoch 174/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0013 - val_loss: 0.0495 - val_accuracy: 0.9896\n",
      "Epoch 175/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0012 - val_loss: 0.0488 - val_accuracy: 0.9896\n",
      "Epoch 176/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0011 - val_loss: 0.0459 - val_accuracy: 0.9896\n",
      "Epoch 177/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0011 - val_loss: 0.0510 - val_accuracy: 0.9896\n",
      "Epoch 178/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0010 - val_loss: 0.0485 - val_accuracy: 0.9896\n",
      "Epoch 179/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0011 - val_loss: 0.0452 - val_accuracy: 0.9896\n",
      "Epoch 180/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 9.5200e-04 - val_loss: 0.0518 - val_accuracy: 0.9896\n",
      "Epoch 181/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 9.4181e-04 - val_loss: 0.0486 - val_accuracy: 0.9896\n",
      "Epoch 182/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 8.7449e-04 - val_loss: 0.0517 - val_accuracy: 0.9896\n",
      "Epoch 183/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 8.6822e-04 - val_loss: 0.0540 - val_accuracy: 0.9896\n",
      "Epoch 184/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 8.0215e-04 - val_loss: 0.0515 - val_accuracy: 0.9896\n",
      "Epoch 185/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 8.0208e-04 - val_loss: 0.0515 - val_accuracy: 0.9896\n",
      "Epoch 186/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 7.5918e-04 - val_loss: 0.0514 - val_accuracy: 0.9896\n",
      "Epoch 187/2000\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 8.1666e-04 - val_loss: 0.0547 - val_accuracy: 0.9896\n",
      "Epoch 188/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 7.4735e-04 - val_loss: 0.0600 - val_accuracy: 0.9896\n",
      "Epoch 189/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0478 - val_loss: 0.1150 - val_accuracy: 0.9375\n",
      "Epoch 190/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.3767 - val_loss: 0.2675 - val_accuracy: 0.9375\n",
      "Epoch 191/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1465 - val_loss: 0.0690 - val_accuracy: 0.9896\n",
      "Epoch 192/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0421 - val_loss: 0.0364 - val_accuracy: 0.9896\n",
      "Epoch 193/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0234 - val_loss: 0.0445 - val_accuracy: 0.9792\n",
      "Epoch 194/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0236 - val_loss: 0.0326 - val_accuracy: 0.9792\n",
      "Epoch 195/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0084 - val_loss: 0.0451 - val_accuracy: 0.9792\n",
      "Epoch 196/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0050 - val_loss: 0.0508 - val_accuracy: 0.9792\n",
      "Epoch 197/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0244 - val_loss: 0.0537 - val_accuracy: 0.9792\n",
      "Epoch 198/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1350 - val_loss: 0.0983 - val_accuracy: 0.9792\n",
      "Epoch 199/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.2593 - val_loss: 0.1149 - val_accuracy: 0.9375\n",
      "Epoch 200/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0797 - val_loss: 0.1039 - val_accuracy: 0.9688\n",
      "Epoch 201/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0230 - val_loss: 0.0289 - val_accuracy: 0.9896\n",
      "Epoch 202/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0211 - val_loss: 0.0560 - val_accuracy: 0.9896\n",
      "Epoch 203/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0066 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 204/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0053 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 205/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0028 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 206/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0021 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 207/2000\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.0016 - val_loss: 0.0108 - val_accuracy: 0.9896\n",
      "Epoch 208/2000\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.0014 - val_loss: 0.0095 - val_accuracy: 0.9896\n",
      "Epoch 209/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0012 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 210/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0042 - val_loss: 0.0404 - val_accuracy: 0.9896\n",
      "Epoch 211/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.5899 - val_loss: 0.3904 - val_accuracy: 0.8750\n",
      "Epoch 212/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.2286 - val_loss: 0.1181 - val_accuracy: 0.9688\n",
      "Epoch 213/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1478 - val_loss: 0.1917 - val_accuracy: 0.9375\n",
      "Epoch 214/2000\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.1904 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
      "Epoch 215/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0499 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 216/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0131 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 217/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0101 - val_loss: 0.0492 - val_accuracy: 0.9896\n",
      "Epoch 218/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0134 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 219/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0138 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 220/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0069 - val_loss: 0.0354 - val_accuracy: 0.9896\n",
      "Epoch 221/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0044 - val_loss: 0.0292 - val_accuracy: 0.9896\n",
      "Epoch 222/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0051 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 223/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0041 - val_loss: 0.0514 - val_accuracy: 0.9896\n",
      "Epoch 224/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0163 - val_loss: 0.0605 - val_accuracy: 0.9792\n",
      "Epoch 225/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0027 - val_loss: 0.0521 - val_accuracy: 0.9792\n",
      "Epoch 226/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0019 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 227/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0017 - val_loss: 0.0324 - val_accuracy: 0.9896\n",
      "Epoch 228/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0015 - val_loss: 0.0275 - val_accuracy: 0.9896\n",
      "Epoch 229/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0013 - val_loss: 0.0383 - val_accuracy: 0.9896\n",
      "Epoch 230/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0073 - val_loss: 0.0497 - val_accuracy: 0.9896\n",
      "Epoch 231/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0295 - val_loss: 0.0369 - val_accuracy: 0.9896\n",
      "Epoch 232/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0125 - val_loss: 0.0284 - val_accuracy: 0.9896\n",
      "Epoch 233/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.0101 - val_loss: 0.0494 - val_accuracy: 0.9896\n",
      "Epoch 234/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0679 - val_loss: 0.1507 - val_accuracy: 0.9479\n",
      "Epoch 235/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1206 - val_loss: 0.1688 - val_accuracy: 0.9271\n",
      "Epoch 236/2000\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.1123 - val_loss: 0.0823 - val_accuracy: 0.9792\n",
      "Epoch 237/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.2011 - val_loss: 0.0684 - val_accuracy: 0.9896\n",
      "Epoch 238/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.2430 - val_loss: 0.2058 - val_accuracy: 0.9375\n",
      "Epoch 239/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.1530 - val_loss: 0.0754 - val_accuracy: 0.9792\n",
      "Epoch 240/2000\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.0831 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
      "Epoch 241/2000\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.0676 - val_loss: 0.0610 - val_accuracy: 0.9792\n",
      "Epoch 242/2000\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.0819Restoring model weights from the end of the best epoch: 142.\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.0819 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
      "Epoch 242: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5e269b2560>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=val_dataset, batch_size=batch_size, epochs=2000,\n",
    "          callbacks=[es_callback])\n",
    "# model.load_weights(\"/content/checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1195,
     "status": "ok",
     "timestamp": 1704197389697,
     "user": {
      "displayName": "Jay Feng",
      "userId": "05408265157775379755"
     },
     "user_tz": -480
    },
    "id": "yOl0S8KPAVTd",
    "outputId": "ab757fb4-3e57-4ba8-ecd3-90d139f97fb7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.00014219692, shape=(), dtype=float32)\n",
      "1.0\n",
      "tf.Tensor(0.00028439384, shape=(), dtype=float32)\n",
      "1.0\n",
      "tf.Tensor(0.00042659076, shape=(), dtype=float32)\n",
      "1.0\n",
      "tf.Tensor(0.0005687877, shape=(), dtype=float32)\n",
      "1.0\n",
      "tf.Tensor(0.00071098463, shape=(), dtype=float32)\n",
      "1.0\n",
      "tf.Tensor(0.0008531816, shape=(), dtype=float32)\n",
      "1.0\n",
      "tf.Tensor(0.0009953785, shape=(), dtype=float32)\n",
      "1.0\n",
      "tf.Tensor(0.0011375754, shape=(), dtype=float32)\n",
      "1.0\n",
      "tf.Tensor(0.0012797724, shape=(), dtype=float32)\n",
      "1.0\n",
      "tf.Tensor(0.0014219693, shape=(), dtype=float32)\n",
      "1.0\n",
      "tf.Tensor(0.0015641662, shape=(), dtype=float32)\n",
      "1.0\n",
      "tf.Tensor(0.0017063632, shape=(), dtype=float32)\n",
      "1.0\n",
      "tf.Tensor(0.0018485601, shape=(), dtype=float32)\n",
      "1.0\n",
      "tf.Tensor(0.001990757, shape=(), dtype=float32)\n",
      "1.0\n",
      "tf.Tensor(0.0021329538, shape=(), dtype=float32)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_hat = model(x_test[0:20], training=True)\n",
    "for i in range(1, 9):\n",
    "    y_hat = np.append(y_hat, model(x_test[20*i:20*i+20], training=False), axis=0)\n",
    "\n",
    "loss = 0\n",
    "for i in range(15):\n",
    "    acc_metric.reset_states()\n",
    "    acc_metric.update_state(y_test, y_hat)\n",
    "    acc = acc_metric.result().numpy()\n",
    "    loss += loss_fn(y_test, y_hat)\n",
    "    print(loss/15)\n",
    "    print(acc)\n",
    "y_hat = np.asarray(y_hat)\n",
    "np.save(f\"fold{fold}.npy\", y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPcJRGDYIsM29GHAAjEuSV/",
   "gpuType": "V100",
   "mount_file_id": "1-fzloUTdrwICSO4OYkMXovzAABmTj3E3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

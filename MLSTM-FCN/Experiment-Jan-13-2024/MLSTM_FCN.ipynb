{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "QmL7j57DYfB3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout, Flatten, Reshape, multiply\n",
    "from keras.layers import Input, Dense, LSTM, concatenate, Activation, GRU, SimpleRNN, Masking\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.load(\"mfcc_fixed.npz\")\n",
    "X, Y = f['X'], f['Y']\n",
    "X_train =  X[0:900]\n",
    "Y_train =  Y[0:900]      # fold 10\n",
    "\n",
    "\n",
    "x_test, y_test = X[900:1000], Y[900:1000]\n",
    "x_train, y_train = X_train[0:800], Y_train[0:800]\n",
    "x_val, y_val= X_train[800:900], Y_train[800:900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=800, reshuffle_each_iteration=True).batch(batch_size, drop_remainder=True)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.shuffle(buffer_size=800, reshuffle_each_iteration=True).batch(batch_size, drop_remainder=True)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=800, reshuffle_each_iteration=True).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "fHCQ-hlyYo8i"
   },
   "outputs": [],
   "source": [
    "def squeeze_excite_block(input):\n",
    "    ''' Create a squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    filters = input.shape[-1] # channel_axis = -1 for TF\n",
    "\n",
    "    se = GlobalAveragePooling1D()(input)\n",
    "    se = Reshape((1, filters))(se)\n",
    "    se = Dense(filters // 16,  activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = multiply([input, se])\n",
    "    return se\n",
    "\n",
    "\n",
    "def build_model(input_shape, batch_size, num_classes):\n",
    "    inputs = Input(shape=input_shape, batch_size=batch_size)     # input_shape=(len, dim)\n",
    "    ip = Permute((2, 1))(inputs)  # input_shape=(dim, len)\n",
    "\n",
    "    x = Masking()(ip)\n",
    "    x = LSTM(8)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs, out)\n",
    "    # model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "RIzwrDX1ZqQ5"
   },
   "outputs": [],
   "source": [
    "model = build_model(X[0].shape, batch_size, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDzieLQ7Z2iG",
    "outputId": "eec25c96-d995-439b-a7ca-a93a8d6a97a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)       [(100, 54, 30)]              0         []                            \n",
      "                                                                                                  \n",
      " permute_26 (Permute)        (100, 30, 54)                0         ['input_14[0][0]']            \n",
      "                                                                                                  \n",
      " permute_27 (Permute)        (100, 54, 30)                0         ['permute_26[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)          (100, 54, 128)               30848     ['permute_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (Ba  (100, 54, 128)               512       ['conv1d_39[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_39 (Activation)  (100, 54, 128)               0         ['batch_normalization_39[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3  (100, 128)                   0         ['activation_39[0][0]']       \n",
      " 9 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " reshape_26 (Reshape)        (100, 1, 128)                0         ['global_average_pooling1d_39[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_65 (Dense)            (100, 1, 8)                  1024      ['reshape_26[0][0]']          \n",
      "                                                                                                  \n",
      " dense_66 (Dense)            (100, 1, 128)                1024      ['dense_65[0][0]']            \n",
      "                                                                                                  \n",
      " multiply_26 (Multiply)      (100, 54, 128)               0         ['activation_39[0][0]',       \n",
      "                                                                     'dense_66[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)          (100, 54, 256)               164096    ['multiply_26[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_40 (Ba  (100, 54, 256)               1024      ['conv1d_40[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_40 (Activation)  (100, 54, 256)               0         ['batch_normalization_40[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4  (100, 256)                   0         ['activation_40[0][0]']       \n",
      " 0 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " reshape_27 (Reshape)        (100, 1, 256)                0         ['global_average_pooling1d_40[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_67 (Dense)            (100, 1, 16)                 4096      ['reshape_27[0][0]']          \n",
      "                                                                                                  \n",
      " dense_68 (Dense)            (100, 1, 256)                4096      ['dense_67[0][0]']            \n",
      "                                                                                                  \n",
      " multiply_27 (Multiply)      (100, 54, 256)               0         ['activation_40[0][0]',       \n",
      "                                                                     'dense_68[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)          (100, 54, 128)               98432     ['multiply_27[0][0]']         \n",
      "                                                                                                  \n",
      " masking_13 (Masking)        (100, 30, 54)                0         ['permute_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (Ba  (100, 54, 128)               512       ['conv1d_41[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_13 (LSTM)              (100, 8)                     2016      ['masking_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_41 (Activation)  (100, 54, 128)               0         ['batch_normalization_41[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (100, 8)                     0         ['lstm_13[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4  (100, 128)                   0         ['activation_41[0][0]']       \n",
      " 1 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenat  (100, 136)                   0         ['dropout_13[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_41[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_69 (Dense)            (100, 5)                     685       ['concatenate_13[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 308365 (1.18 MB)\n",
      "Trainable params: 307341 (1.17 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "Hux34tg9oNo5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "8/8 [==============================] - 5s 137ms/step - loss: 0.9964 - accuracy: 0.6237 - val_loss: 4.0395 - val_accuracy: 0.2700 - lr: 0.0010\n",
      "Epoch 2/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3351 - accuracy: 0.9200 - val_loss: 7.7458 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 3/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1850 - accuracy: 0.9563 - val_loss: 9.5296 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 4/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1316 - accuracy: 0.9638 - val_loss: 10.0119 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 5/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0807 - accuracy: 0.9900 - val_loss: 9.3525 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 6/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0676 - accuracy: 0.9812 - val_loss: 8.4579 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 7/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0459 - accuracy: 0.9950 - val_loss: 7.1095 - val_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 8/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0340 - accuracy: 0.9962 - val_loss: 5.9180 - val_accuracy: 0.2100 - lr: 0.0010\n",
      "Epoch 9/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0315 - accuracy: 0.9925 - val_loss: 5.2952 - val_accuracy: 0.2200 - lr: 0.0010\n",
      "Epoch 10/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9987 - val_loss: 4.8909 - val_accuracy: 0.2400 - lr: 0.0010\n",
      "Epoch 11/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 3.5787 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 12/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0144 - accuracy: 0.9987 - val_loss: 3.4121 - val_accuracy: 0.2600 - lr: 0.0010\n",
      "Epoch 13/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.4334 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 14/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0107 - accuracy: 0.9987 - val_loss: 1.9821 - val_accuracy: 0.3700 - lr: 0.0010\n",
      "Epoch 15/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0119 - accuracy: 0.9987 - val_loss: 1.6445 - val_accuracy: 0.3800 - lr: 0.0010\n",
      "Epoch 16/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 0.9987 - val_loss: 1.0887 - val_accuracy: 0.5100 - lr: 0.0010\n",
      "Epoch 17/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8272 - val_accuracy: 0.6300 - lr: 0.0010\n",
      "Epoch 18/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.6700 - lr: 0.0010\n",
      "Epoch 19/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6302 - val_accuracy: 0.6800 - lr: 0.0010\n",
      "Epoch 20/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4843 - val_accuracy: 0.7800 - lr: 0.0010\n",
      "Epoch 21/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3216 - val_accuracy: 0.8300 - lr: 0.0010\n",
      "Epoch 22/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9300 - lr: 0.0010\n",
      "Epoch 23/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 24/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "Epoch 25/2000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9900 - lr: 0.0010\n",
      "Epoch 26/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9900 - lr: 0.0010\n",
      "Epoch 27/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9900 - lr: 0.0010\n",
      "Epoch 28/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9900 - lr: 0.0010\n",
      "Epoch 29/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 30/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 31/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 32/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 33/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 34/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 35/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 36/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 37/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 38/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 39/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 40/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 41/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 9.8694e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 42/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 43/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 44/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 45/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 46/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 9.2455e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 47/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 48/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.6368e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 49/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 7.8341e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 50/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 51/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 7.9196e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 52/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 7.1902e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 53/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 6.8459e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 54/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 7.3208e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 55/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 6.9523e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 56/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 6.6445e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 57/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7.6810e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 58/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 6.7060e-04 - accuracy: 1.0000 - val_loss: 9.8786e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 59/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.5734e-04 - accuracy: 1.0000 - val_loss: 9.3437e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 60/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.2376e-04 - accuracy: 1.0000 - val_loss: 8.6747e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 61/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.6741e-04 - accuracy: 1.0000 - val_loss: 8.0625e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 62/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 5.6986e-04 - accuracy: 1.0000 - val_loss: 7.3476e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 63/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.5232e-04 - accuracy: 1.0000 - val_loss: 7.3677e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 64/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.3867e-04 - accuracy: 1.0000 - val_loss: 7.4135e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 65/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 4.8790e-04 - accuracy: 1.0000 - val_loss: 7.2987e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 66/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 5.4244e-04 - accuracy: 1.0000 - val_loss: 6.7834e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 67/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.6059e-04 - accuracy: 1.0000 - val_loss: 6.4543e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 68/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.9482e-04 - accuracy: 1.0000 - val_loss: 6.5132e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 69/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.6730e-04 - accuracy: 1.0000 - val_loss: 6.6560e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 70/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.9912e-04 - accuracy: 1.0000 - val_loss: 6.8017e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 71/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.0213e-04 - accuracy: 1.0000 - val_loss: 5.9307e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 72/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.5377e-04 - accuracy: 1.0000 - val_loss: 5.5651e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 73/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.3034e-04 - accuracy: 1.0000 - val_loss: 5.3779e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 74/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.8198e-04 - accuracy: 1.0000 - val_loss: 5.2612e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 75/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.3879e-04 - accuracy: 1.0000 - val_loss: 5.4692e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 76/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.7698e-04 - accuracy: 1.0000 - val_loss: 5.4726e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 77/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.0063e-04 - accuracy: 1.0000 - val_loss: 5.4680e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 78/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.9993e-04 - accuracy: 1.0000 - val_loss: 5.1226e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 79/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.1870e-04 - accuracy: 1.0000 - val_loss: 4.3486e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 80/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 4.5669e-04 - accuracy: 1.0000 - val_loss: 4.1624e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 81/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.0475e-04 - accuracy: 1.0000 - val_loss: 4.1632e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 82/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.8098e-04 - accuracy: 1.0000 - val_loss: 4.2258e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 83/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.6161e-04 - accuracy: 1.0000 - val_loss: 3.9239e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 84/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.4784e-04 - accuracy: 1.0000 - val_loss: 3.8492e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 85/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.7018e-04 - accuracy: 1.0000 - val_loss: 3.9654e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 86/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.4190e-04 - accuracy: 1.0000 - val_loss: 4.0387e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 87/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.3515e-04 - accuracy: 1.0000 - val_loss: 3.7453e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 88/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.9690e-04 - accuracy: 1.0000 - val_loss: 3.8592e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 89/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.1545e-04 - accuracy: 1.0000 - val_loss: 3.9222e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 90/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 4.6825e-04 - accuracy: 1.0000 - val_loss: 4.1291e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 91/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.2050e-04 - accuracy: 1.0000 - val_loss: 4.1546e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 92/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.0697e-04 - accuracy: 1.0000 - val_loss: 4.0757e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 93/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.5835e-04 - accuracy: 1.0000 - val_loss: 4.0316e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 94/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.3805e-04 - accuracy: 1.0000 - val_loss: 4.5195e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 95/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.5113e-04 - accuracy: 1.0000 - val_loss: 5.1321e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 96/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.6351e-04 - accuracy: 1.0000 - val_loss: 4.7857e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 97/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.7764e-04 - accuracy: 1.0000 - val_loss: 4.5129e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 98/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.4403e-04 - accuracy: 1.0000 - val_loss: 4.2277e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 99/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.3398e-04 - accuracy: 1.0000 - val_loss: 4.1537e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 100/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.0396e-04 - accuracy: 1.0000 - val_loss: 3.9234e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 101/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.8451e-04 - accuracy: 1.0000 - val_loss: 3.4131e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 102/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.7900e-04 - accuracy: 1.0000 - val_loss: 3.4744e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 103/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.8956e-04 - accuracy: 1.0000 - val_loss: 3.7009e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 104/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.5818e-04 - accuracy: 1.0000 - val_loss: 3.6705e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 105/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.2303e-04 - accuracy: 1.0000 - val_loss: 3.6735e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 106/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.3644e-04 - accuracy: 1.0000 - val_loss: 3.7322e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 107/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.8538e-04 - accuracy: 1.0000 - val_loss: 3.6281e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 108/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.1652e-04 - accuracy: 1.0000 - val_loss: 3.5967e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 109/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.9767e-04 - accuracy: 1.0000 - val_loss: 3.5538e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 110/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7846e-04 - accuracy: 1.0000 - val_loss: 3.5196e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 111/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.7618e-04 - accuracy: 1.0000 - val_loss: 3.6380e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 112/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.8040e-04 - accuracy: 1.0000 - val_loss: 3.9095e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 113/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.2862e-04 - accuracy: 1.0000 - val_loss: 3.9165e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 114/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.0821e-04 - accuracy: 1.0000 - val_loss: 3.6664e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 115/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.5380e-04 - accuracy: 1.0000 - val_loss: 3.5372e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 116/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.0262e-04 - accuracy: 1.0000 - val_loss: 3.5675e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 117/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6525e-04 - accuracy: 1.0000 - val_loss: 3.3374e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 118/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7899e-04 - accuracy: 1.0000 - val_loss: 3.1162e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 119/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.4970e-04 - accuracy: 1.0000 - val_loss: 2.9740e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 120/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.0542e-04 - accuracy: 1.0000 - val_loss: 3.1888e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 121/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6590e-04 - accuracy: 1.0000 - val_loss: 3.4432e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 122/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7250e-04 - accuracy: 1.0000 - val_loss: 3.7046e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 123/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7783e-04 - accuracy: 1.0000 - val_loss: 3.7025e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 124/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.8921e-04 - accuracy: 1.0000 - val_loss: 3.1904e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 125/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.4859e-04 - accuracy: 1.0000 - val_loss: 3.0520e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 126/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.5256e-04 - accuracy: 1.0000 - val_loss: 2.8554e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 127/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6399e-04 - accuracy: 1.0000 - val_loss: 2.8380e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 128/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6923e-04 - accuracy: 1.0000 - val_loss: 2.8083e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 129/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.8281e-04 - accuracy: 1.0000 - val_loss: 2.4454e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 130/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.3599e-04 - accuracy: 1.0000 - val_loss: 2.1957e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 131/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.0805e-04 - accuracy: 1.0000 - val_loss: 2.0660e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 132/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.7105e-04 - accuracy: 1.0000 - val_loss: 1.8942e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 133/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.2183e-04 - accuracy: 1.0000 - val_loss: 1.8320e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 134/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.4870e-04 - accuracy: 1.0000 - val_loss: 1.8568e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 135/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6058e-04 - accuracy: 1.0000 - val_loss: 1.8939e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 136/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.5494e-04 - accuracy: 1.0000 - val_loss: 2.1829e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 137/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7532e-04 - accuracy: 1.0000 - val_loss: 2.2612e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 138/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.0176e-04 - accuracy: 1.0000 - val_loss: 2.4029e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 139/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7846e-04 - accuracy: 1.0000 - val_loss: 1.9467e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 140/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.3304e-04 - accuracy: 1.0000 - val_loss: 1.6793e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 141/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.3814e-04 - accuracy: 1.0000 - val_loss: 1.5759e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 142/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.5780e-04 - accuracy: 1.0000 - val_loss: 1.6506e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 143/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.3525e-04 - accuracy: 1.0000 - val_loss: 1.8099e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 144/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0903e-04 - accuracy: 1.0000 - val_loss: 1.9208e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 145/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.2995e-04 - accuracy: 1.0000 - val_loss: 2.0174e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 146/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0358e-04 - accuracy: 1.0000 - val_loss: 2.1258e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 147/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.3339e-04 - accuracy: 1.0000 - val_loss: 2.2716e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 148/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.4640e-04 - accuracy: 1.0000 - val_loss: 2.3853e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 149/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.4316e-04 - accuracy: 1.0000 - val_loss: 2.4094e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 150/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.1907e-04 - accuracy: 1.0000 - val_loss: 2.4249e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 151/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1191e-04 - accuracy: 1.0000 - val_loss: 2.4371e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 152/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.2531e-04 - accuracy: 1.0000 - val_loss: 2.4682e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 153/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6138e-04 - accuracy: 1.0000 - val_loss: 2.2700e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 154/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6980e-04 - accuracy: 1.0000 - val_loss: 2.2004e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 155/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.3009e-04 - accuracy: 1.0000 - val_loss: 2.0472e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 156/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.3076e-04 - accuracy: 1.0000 - val_loss: 2.2566e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 157/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.2989e-04 - accuracy: 1.0000 - val_loss: 2.5673e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 158/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.3209e-04 - accuracy: 1.0000 - val_loss: 2.7583e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 159/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1545e-04 - accuracy: 1.0000 - val_loss: 3.0769e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 160/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.1787e-04 - accuracy: 1.0000 - val_loss: 3.1066e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 161/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 9.7994e-05 - accuracy: 1.0000 - val_loss: 2.9297e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 162/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0443e-04 - accuracy: 1.0000 - val_loss: 2.5766e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 163/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.1935e-04 - accuracy: 1.0000 - val_loss: 2.3593e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 164/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0802e-04 - accuracy: 1.0000 - val_loss: 2.2059e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 165/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.4652e-04 - accuracy: 1.0000 - val_loss: 2.3857e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 166/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.1511e-04 - accuracy: 1.0000 - val_loss: 2.3587e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 167/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 9.4458e-05 - accuracy: 1.0000 - val_loss: 2.1867e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 168/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0729e-04 - accuracy: 1.0000 - val_loss: 2.0994e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 169/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 9.0085e-05 - accuracy: 1.0000 - val_loss: 2.0020e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 170/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.9270e-05 - accuracy: 1.0000 - val_loss: 1.7933e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 171/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.7970e-05 - accuracy: 1.0000 - val_loss: 1.7394e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 172/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.9576e-05 - accuracy: 1.0000 - val_loss: 1.7401e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 173/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7.9707e-05 - accuracy: 1.0000 - val_loss: 1.6405e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 174/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.4432e-05 - accuracy: 1.0000 - val_loss: 1.6015e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 175/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.2235e-04 - accuracy: 1.0000 - val_loss: 1.6120e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 176/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.9339e-05 - accuracy: 1.0000 - val_loss: 1.7690e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 177/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.1936e-04 - accuracy: 1.0000 - val_loss: 1.8414e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 178/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 9.0513e-05 - accuracy: 1.0000 - val_loss: 1.9517e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 179/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 9.9213e-05 - accuracy: 1.0000 - val_loss: 1.9585e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 180/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0651e-04 - accuracy: 1.0000 - val_loss: 1.9616e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 181/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 9.5906e-05 - accuracy: 1.0000 - val_loss: 1.9770e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 182/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0413e-04 - accuracy: 1.0000 - val_loss: 1.9119e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 183/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0744e-04 - accuracy: 1.0000 - val_loss: 1.7473e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 184/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0608e-04 - accuracy: 1.0000 - val_loss: 1.6205e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 185/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 6.8385e-05 - accuracy: 1.0000 - val_loss: 1.4462e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 186/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.3661e-05 - accuracy: 1.0000 - val_loss: 1.3240e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 187/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.7040e-05 - accuracy: 1.0000 - val_loss: 1.2958e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 188/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.4619e-05 - accuracy: 1.0000 - val_loss: 1.2570e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 189/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.1565e-05 - accuracy: 1.0000 - val_loss: 1.2624e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 190/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7.8678e-05 - accuracy: 1.0000 - val_loss: 1.2326e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 191/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7.3156e-05 - accuracy: 1.0000 - val_loss: 1.1613e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 192/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.6809e-05 - accuracy: 1.0000 - val_loss: 1.1657e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 193/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.5829e-05 - accuracy: 1.0000 - val_loss: 1.1957e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 194/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.6001e-05 - accuracy: 1.0000 - val_loss: 1.2967e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 195/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.1305e-05 - accuracy: 1.0000 - val_loss: 1.3895e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 196/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.0048e-05 - accuracy: 1.0000 - val_loss: 1.4409e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 197/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.0189e-05 - accuracy: 1.0000 - val_loss: 1.4717e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 198/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.4692e-05 - accuracy: 1.0000 - val_loss: 1.3849e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 199/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.4604e-05 - accuracy: 1.0000 - val_loss: 1.2139e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 200/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 9.3482e-05 - accuracy: 1.0000 - val_loss: 1.1339e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 201/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.6484e-05 - accuracy: 1.0000 - val_loss: 1.2559e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 202/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.9405e-05 - accuracy: 1.0000 - val_loss: 1.5221e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 203/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7.0801e-05 - accuracy: 1.0000 - val_loss: 1.4820e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 204/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.5140e-05 - accuracy: 1.0000 - val_loss: 1.3775e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 205/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.4993e-05 - accuracy: 1.0000 - val_loss: 1.2660e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 206/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 9.0423e-05 - accuracy: 1.0000 - val_loss: 1.2531e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 207/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.1318e-05 - accuracy: 1.0000 - val_loss: 1.2135e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 208/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.0474e-05 - accuracy: 1.0000 - val_loss: 1.2020e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 209/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.4615e-05 - accuracy: 1.0000 - val_loss: 1.2320e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 210/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.8714e-05 - accuracy: 1.0000 - val_loss: 1.3842e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 211/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.5741e-05 - accuracy: 1.0000 - val_loss: 1.5113e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 212/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.6367e-05 - accuracy: 1.0000 - val_loss: 1.4738e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 213/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.8871e-05 - accuracy: 1.0000 - val_loss: 1.4273e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 214/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0144e-04 - accuracy: 1.0000 - val_loss: 1.5362e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 215/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7.1550e-05 - accuracy: 1.0000 - val_loss: 1.7046e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 216/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.7755e-05 - accuracy: 1.0000 - val_loss: 1.7319e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 217/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 9.5804e-05 - accuracy: 1.0000 - val_loss: 2.3537e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 218/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 6.0205e-05 - accuracy: 1.0000 - val_loss: 2.5013e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 219/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7.6674e-05 - accuracy: 1.0000 - val_loss: 1.9761e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 220/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.4050e-05 - accuracy: 1.0000 - val_loss: 1.4609e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 221/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 6.1493e-05 - accuracy: 1.0000 - val_loss: 1.2075e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 222/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 9.3016e-05 - accuracy: 1.0000 - val_loss: 1.2638e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 223/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.1451e-05 - accuracy: 1.0000 - val_loss: 1.3705e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 224/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.9180e-05 - accuracy: 1.0000 - val_loss: 1.2839e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 225/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.4935e-05 - accuracy: 1.0000 - val_loss: 1.2534e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 226/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.2216e-05 - accuracy: 1.0000 - val_loss: 1.2409e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 227/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.6292e-05 - accuracy: 1.0000 - val_loss: 1.1386e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 228/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.8204e-05 - accuracy: 1.0000 - val_loss: 1.0891e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 229/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.5121e-05 - accuracy: 1.0000 - val_loss: 1.0025e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 230/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.1032e-05 - accuracy: 1.0000 - val_loss: 9.7044e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 231/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.7477e-05 - accuracy: 1.0000 - val_loss: 9.6743e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 232/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.5861e-05 - accuracy: 1.0000 - val_loss: 9.9953e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 233/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.3655e-05 - accuracy: 1.0000 - val_loss: 1.0861e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 234/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.4073e-05 - accuracy: 1.0000 - val_loss: 1.1093e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 235/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.3413e-05 - accuracy: 1.0000 - val_loss: 1.1202e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 236/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.5722e-05 - accuracy: 1.0000 - val_loss: 1.1010e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 237/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.2719e-05 - accuracy: 1.0000 - val_loss: 1.0103e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 238/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.5930e-05 - accuracy: 1.0000 - val_loss: 9.7710e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 239/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.2347e-05 - accuracy: 1.0000 - val_loss: 9.8462e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 240/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.4969e-05 - accuracy: 1.0000 - val_loss: 1.0326e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 241/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.6503e-05 - accuracy: 1.0000 - val_loss: 1.5285e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 242/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.1734e-05 - accuracy: 1.0000 - val_loss: 1.4784e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 243/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7.0427e-05 - accuracy: 1.0000 - val_loss: 1.3640e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 244/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.5166e-05 - accuracy: 1.0000 - val_loss: 1.2275e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 245/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.3261e-05 - accuracy: 1.0000 - val_loss: 1.2740e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 246/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.2823e-05 - accuracy: 1.0000 - val_loss: 1.1875e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 247/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.9138e-05 - accuracy: 1.0000 - val_loss: 1.1692e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 248/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.5589e-05 - accuracy: 1.0000 - val_loss: 1.2264e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 249/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.0134e-05 - accuracy: 1.0000 - val_loss: 1.1255e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 250/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 4.0074e-05 - accuracy: 1.0000 - val_loss: 8.6422e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 251/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.4620e-05 - accuracy: 1.0000 - val_loss: 7.8571e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 252/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.2292e-05 - accuracy: 1.0000 - val_loss: 7.4419e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 253/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.0667e-05 - accuracy: 1.0000 - val_loss: 7.4385e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 254/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.4201e-05 - accuracy: 1.0000 - val_loss: 7.5896e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 255/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.7575e-05 - accuracy: 1.0000 - val_loss: 7.6433e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 256/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.2867e-05 - accuracy: 1.0000 - val_loss: 7.9019e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 257/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.7040e-05 - accuracy: 1.0000 - val_loss: 8.4491e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 258/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.2811e-05 - accuracy: 1.0000 - val_loss: 9.9741e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 259/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.9360e-05 - accuracy: 1.0000 - val_loss: 1.0691e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 260/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.5997e-05 - accuracy: 1.0000 - val_loss: 1.1023e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 261/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.6296e-05 - accuracy: 1.0000 - val_loss: 1.0793e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 262/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.8893e-05 - accuracy: 1.0000 - val_loss: 1.1045e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 263/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.4900e-05 - accuracy: 1.0000 - val_loss: 1.4536e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 264/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.7027e-05 - accuracy: 1.0000 - val_loss: 1.5644e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 265/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.0183e-05 - accuracy: 1.0000 - val_loss: 1.4467e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 266/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.8502e-05 - accuracy: 1.0000 - val_loss: 1.2832e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 267/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.3437e-05 - accuracy: 1.0000 - val_loss: 1.0424e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 268/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 5.1109e-05 - accuracy: 1.0000 - val_loss: 6.6735e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 269/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.8997e-05 - accuracy: 1.0000 - val_loss: 5.1347e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 270/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 4.2662e-05 - accuracy: 1.0000 - val_loss: 4.8727e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 271/2000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 4.3530e-05 - accuracy: 1.0000 - val_loss: 4.9959e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 272/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 3.7178e-05 - accuracy: 1.0000 - val_loss: 5.1161e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 273/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.9765e-05 - accuracy: 1.0000 - val_loss: 5.3339e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 274/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7.2569e-05 - accuracy: 1.0000 - val_loss: 6.5047e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 275/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.5129e-05 - accuracy: 1.0000 - val_loss: 7.6712e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 276/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.0619e-05 - accuracy: 1.0000 - val_loss: 8.0810e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 277/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.4519e-05 - accuracy: 1.0000 - val_loss: 7.2468e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 278/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.5949e-05 - accuracy: 1.0000 - val_loss: 6.8585e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 279/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.7578e-05 - accuracy: 1.0000 - val_loss: 6.6729e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 280/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.5478e-05 - accuracy: 1.0000 - val_loss: 6.6695e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 281/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.1905e-05 - accuracy: 1.0000 - val_loss: 6.5051e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 282/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.7513e-05 - accuracy: 1.0000 - val_loss: 6.2191e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 283/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.3225e-05 - accuracy: 1.0000 - val_loss: 6.3345e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 284/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.2186e-05 - accuracy: 1.0000 - val_loss: 6.3340e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 285/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.0653e-05 - accuracy: 1.0000 - val_loss: 7.4943e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 286/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.2648e-05 - accuracy: 1.0000 - val_loss: 9.1098e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 287/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.2571e-05 - accuracy: 1.0000 - val_loss: 9.9053e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 288/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.1542e-05 - accuracy: 1.0000 - val_loss: 9.2065e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 289/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.7103e-05 - accuracy: 1.0000 - val_loss: 8.7733e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 290/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.4873e-05 - accuracy: 1.0000 - val_loss: 8.6635e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 291/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.7769e-05 - accuracy: 1.0000 - val_loss: 8.4569e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 292/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.4003e-05 - accuracy: 1.0000 - val_loss: 8.0705e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 293/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.0096e-05 - accuracy: 1.0000 - val_loss: 7.8701e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 294/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.2957e-05 - accuracy: 1.0000 - val_loss: 7.9242e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 295/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.1548e-05 - accuracy: 1.0000 - val_loss: 7.7612e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 296/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.9542e-05 - accuracy: 1.0000 - val_loss: 7.5920e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 297/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.1420e-05 - accuracy: 1.0000 - val_loss: 7.0617e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 298/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.1746e-05 - accuracy: 1.0000 - val_loss: 6.7968e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 299/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.2794e-05 - accuracy: 1.0000 - val_loss: 5.3671e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 300/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.2418e-05 - accuracy: 1.0000 - val_loss: 4.3464e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 301/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.8588e-05 - accuracy: 1.0000 - val_loss: 4.0593e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 302/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.4030e-05 - accuracy: 1.0000 - val_loss: 4.0419e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 303/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.9704e-05 - accuracy: 1.0000 - val_loss: 4.2395e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 304/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.5041e-05 - accuracy: 1.0000 - val_loss: 4.8761e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 305/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.8324e-05 - accuracy: 1.0000 - val_loss: 5.4366e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 306/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.6867e-05 - accuracy: 1.0000 - val_loss: 5.6335e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 307/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.2812e-05 - accuracy: 1.0000 - val_loss: 5.9186e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 308/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.7906e-05 - accuracy: 1.0000 - val_loss: 6.5574e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 309/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.7326e-05 - accuracy: 1.0000 - val_loss: 7.3486e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 310/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.4392e-05 - accuracy: 1.0000 - val_loss: 7.5241e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 311/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.0614e-05 - accuracy: 1.0000 - val_loss: 7.3160e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 312/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.5526e-05 - accuracy: 1.0000 - val_loss: 7.3817e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 313/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.2905e-05 - accuracy: 1.0000 - val_loss: 7.9618e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 314/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.5774e-05 - accuracy: 1.0000 - val_loss: 8.1611e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 315/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.8985e-05 - accuracy: 1.0000 - val_loss: 8.1882e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 316/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.2795e-05 - accuracy: 1.0000 - val_loss: 7.7917e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 317/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.3780e-05 - accuracy: 1.0000 - val_loss: 7.4382e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 318/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.8798e-05 - accuracy: 1.0000 - val_loss: 7.0179e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 319/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.0042e-05 - accuracy: 1.0000 - val_loss: 6.9065e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 320/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.1375e-05 - accuracy: 1.0000 - val_loss: 6.7848e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 321/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.4148e-05 - accuracy: 1.0000 - val_loss: 6.6693e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 322/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.4770e-05 - accuracy: 1.0000 - val_loss: 6.5501e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 323/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.0718e-05 - accuracy: 1.0000 - val_loss: 6.4019e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 324/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.2017e-05 - accuracy: 1.0000 - val_loss: 6.2998e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 325/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.7331e-05 - accuracy: 1.0000 - val_loss: 6.3451e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 326/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.7833e-05 - accuracy: 1.0000 - val_loss: 6.3449e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 327/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.8749e-05 - accuracy: 1.0000 - val_loss: 6.2082e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 328/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.7523e-05 - accuracy: 1.0000 - val_loss: 5.8929e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 329/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.2515e-05 - accuracy: 1.0000 - val_loss: 5.7252e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 330/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.2974e-05 - accuracy: 1.0000 - val_loss: 5.6463e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 331/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.0769e-05 - accuracy: 1.0000 - val_loss: 5.8572e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 332/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.6594e-05 - accuracy: 1.0000 - val_loss: 5.8721e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 333/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.8800e-05 - accuracy: 1.0000 - val_loss: 5.7814e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 334/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.9871e-05 - accuracy: 1.0000 - val_loss: 5.9767e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 335/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.7898e-05 - accuracy: 1.0000 - val_loss: 5.1478e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 336/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.1359e-05 - accuracy: 1.0000 - val_loss: 4.8054e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 337/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.8857e-05 - accuracy: 1.0000 - val_loss: 4.6964e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 338/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.8477e-05 - accuracy: 1.0000 - val_loss: 4.7355e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 339/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.6546e-05 - accuracy: 1.0000 - val_loss: 4.7975e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 340/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.3467e-05 - accuracy: 1.0000 - val_loss: 4.8700e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 341/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.5155e-05 - accuracy: 1.0000 - val_loss: 4.7712e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 342/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.4857e-05 - accuracy: 1.0000 - val_loss: 4.9107e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 343/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.8847e-05 - accuracy: 1.0000 - val_loss: 5.4326e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 344/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.3060e-05 - accuracy: 1.0000 - val_loss: 5.3869e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 345/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.2113e-05 - accuracy: 1.0000 - val_loss: 5.2909e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 346/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.9922e-05 - accuracy: 1.0000 - val_loss: 5.3674e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 347/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.9750e-05 - accuracy: 1.0000 - val_loss: 5.6127e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 348/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.6840e-05 - accuracy: 1.0000 - val_loss: 5.8433e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 349/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.8632e-05 - accuracy: 1.0000 - val_loss: 5.8427e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 350/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.1858e-05 - accuracy: 1.0000 - val_loss: 6.0313e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 351/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.4257e-05 - accuracy: 1.0000 - val_loss: 6.0734e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 352/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.4093e-05 - accuracy: 1.0000 - val_loss: 6.0942e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 353/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.0800e-05 - accuracy: 1.0000 - val_loss: 6.1483e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 354/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.0811e-05 - accuracy: 1.0000 - val_loss: 5.9929e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 355/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.1628e-05 - accuracy: 1.0000 - val_loss: 5.6225e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 356/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.8627e-05 - accuracy: 1.0000 - val_loss: 5.6688e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 357/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.8236e-05 - accuracy: 1.0000 - val_loss: 6.4712e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 358/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.7075e-05 - accuracy: 1.0000 - val_loss: 6.3869e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 359/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.3178e-05 - accuracy: 1.0000 - val_loss: 4.3051e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 360/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.4235e-05 - accuracy: 1.0000 - val_loss: 4.0793e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 361/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.8224e-05 - accuracy: 1.0000 - val_loss: 4.3994e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 362/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.6102e-05 - accuracy: 1.0000 - val_loss: 4.3935e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 363/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 4.2273e-05 - accuracy: 1.0000 - val_loss: 4.4137e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 364/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.4988e-05 - accuracy: 1.0000 - val_loss: 4.6538e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 365/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.8446e-05 - accuracy: 1.0000 - val_loss: 4.7938e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 366/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.0280e-05 - accuracy: 1.0000 - val_loss: 4.6992e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 367/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.9072e-05 - accuracy: 1.0000 - val_loss: 4.6382e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 368/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.3692e-05 - accuracy: 1.0000 - val_loss: 4.4022e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 369/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.1928e-05 - accuracy: 1.0000 - val_loss: 4.1860e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 370/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.8831e-05 - accuracy: 1.0000 - val_loss: 4.8512e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 371/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.9148e-05 - accuracy: 1.0000 - val_loss: 5.2022e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 372/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.5274e-05 - accuracy: 1.0000 - val_loss: 4.9325e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 373/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.6190e-05 - accuracy: 1.0000 - val_loss: 4.8260e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 374/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.2912e-05 - accuracy: 1.0000 - val_loss: 5.1665e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 375/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.5063e-05 - accuracy: 1.0000 - val_loss: 5.3217e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 376/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.1489e-05 - accuracy: 1.0000 - val_loss: 5.4333e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 377/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7288e-05 - accuracy: 1.0000 - val_loss: 5.1725e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 378/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.4173e-05 - accuracy: 1.0000 - val_loss: 4.9539e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 379/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.0117e-05 - accuracy: 1.0000 - val_loss: 4.9521e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 380/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.8117e-05 - accuracy: 1.0000 - val_loss: 5.1472e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 381/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.4448e-05 - accuracy: 1.0000 - val_loss: 4.6759e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 382/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7644e-05 - accuracy: 1.0000 - val_loss: 4.5556e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 383/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.3764e-05 - accuracy: 1.0000 - val_loss: 4.4223e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 384/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.4546e-05 - accuracy: 1.0000 - val_loss: 4.2953e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 385/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.9466e-05 - accuracy: 1.0000 - val_loss: 4.1296e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 386/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.2435e-05 - accuracy: 1.0000 - val_loss: 4.0918e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 387/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.1523e-05 - accuracy: 1.0000 - val_loss: 4.0554e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 388/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7517e-05 - accuracy: 1.0000 - val_loss: 4.1093e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 389/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.3886e-05 - accuracy: 1.0000 - val_loss: 4.1862e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 390/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7205e-05 - accuracy: 1.0000 - val_loss: 4.0982e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 391/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.0756e-05 - accuracy: 1.0000 - val_loss: 4.1148e-05 - val_accuracy: 1.0000 - lr: 7.9370e-04\n",
      "Epoch 392/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.9765e-05 - accuracy: 1.0000 - val_loss: 4.1218e-05 - val_accuracy: 1.0000 - lr: 6.2996e-04\n",
      "Epoch 393/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.4841e-05 - accuracy: 1.0000 - val_loss: 4.1717e-05 - val_accuracy: 1.0000 - lr: 6.2996e-04\n",
      "Epoch 394/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.7824e-05 - accuracy: 1.0000 - val_loss: 4.2824e-05 - val_accuracy: 1.0000 - lr: 6.2996e-04\n",
      "Epoch 395/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.6164e-05 - accuracy: 1.0000 - val_loss: 4.4409e-05 - val_accuracy: 1.0000 - lr: 6.2996e-04\n",
      "Epoch 396/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.1922e-05 - accuracy: 1.0000 - val_loss: 4.7164e-05 - val_accuracy: 1.0000 - lr: 6.2996e-04\n",
      "Epoch 397/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.0891e-05 - accuracy: 1.0000 - val_loss: 5.0052e-05 - val_accuracy: 1.0000 - lr: 6.2996e-04\n",
      "Epoch 398/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.9306e-05 - accuracy: 1.0000 - val_loss: 5.0941e-05 - val_accuracy: 1.0000 - lr: 6.2996e-04\n",
      "Epoch 399/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.0029e-05 - accuracy: 1.0000 - val_loss: 5.2028e-05 - val_accuracy: 1.0000 - lr: 6.2996e-04\n",
      "Epoch 400/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.8825e-05 - accuracy: 1.0000 - val_loss: 5.2267e-05 - val_accuracy: 1.0000 - lr: 6.2996e-04\n",
      "Epoch 401/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.2801e-05 - accuracy: 1.0000 - val_loss: 5.1160e-05 - val_accuracy: 1.0000 - lr: 6.2996e-04\n",
      "Epoch 402/2000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.9198e-05 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 302.\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.0374e-05 - accuracy: 1.0000 - val_loss: 4.4792e-05 - val_accuracy: 1.0000 - lr: 6.2996e-04\n",
      "Epoch 402: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f819632f9d0>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if lr > 1e-4:\n",
    "        return lr * np.floor(epoch/100)*(1-0.7937005259841)\n",
    "    else:\n",
    "        return lr\n",
    "    \n",
    "rLRoP_callback = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                                    factor=0.7937005259841,\n",
    "                                                    patience=100,\n",
    "                                                    verbose=0,\n",
    "                                                    mode=\"auto\",\n",
    "                                                    min_delta=0.0001,\n",
    "                                                    cooldown=0,\n",
    "                                                    min_lr=1e-4)\n",
    "es_callback = keras.callbacks.EarlyStopping(\n",
    "                                            monitor=\"val_loss\",\n",
    "                                            min_delta=0,\n",
    "                                            patience=100,\n",
    "                                            verbose=1,\n",
    "                                            mode=\"auto\",\n",
    "                                            baseline=None,\n",
    "                                            restore_best_weights=True,\n",
    "                                            start_from_epoch=0,\n",
    "                                           )\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "model.fit(train_dataset, validation_data=val_dataset, batch_size=batch_size, epochs=2000,\n",
    "          callbacks=[es_callback, rLRoP_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "blAtsKjqtswc",
    "outputId": "b6dbff21-af8b-4d6d-99da-ee5332b71705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 6.335396e-05\n"
     ]
    }
   ],
   "source": [
    "acc_metric.reset_states()\n",
    "acc_metric.update_state(y_test, model(x_test))\n",
    "acc = acc_metric.result().numpy()\n",
    "loss = loss_fn(y_test, model(x_test)).numpy()\n",
    "print(acc, loss)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

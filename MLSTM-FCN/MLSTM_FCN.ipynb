{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QmL7j57DYfB3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout, Flatten, Reshape, multiply\n",
        "from keras.layers import Input, Dense, LSTM, concatenate, Activation, GRU, SimpleRNN, Masking\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fHCQ-hlyYo8i"
      },
      "outputs": [],
      "source": [
        "def squeeze_excite_block(input):\n",
        "    ''' Create a squeeze-excite block\n",
        "    Args:\n",
        "        input: input tensor\n",
        "        filters: number of output filters\n",
        "        k: width factor\n",
        "\n",
        "    Returns: a keras tensor\n",
        "    '''\n",
        "    filters = input.shape[-1] # channel_axis = -1 for TF\n",
        "\n",
        "    se = GlobalAveragePooling1D()(input)\n",
        "    se = Reshape((1, filters))(se)\n",
        "    se = Dense(filters // 16,  activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = multiply([input, se])\n",
        "    return se\n",
        "\n",
        "\n",
        "def build_model(input_shape, batch_size, num_classes):\n",
        "    inputs = Input(shape=input_shape, batch_size=batch_size)     # input_shape=(len, dim)\n",
        "    ip = Permute((2, 1))(inputs)  # input_shape=(dim, len)\n",
        "\n",
        "    x = Masking()(ip)\n",
        "    x = LSTM(8)(x)\n",
        "    x = Dropout(0.8)(x)\n",
        "\n",
        "    y = Permute((2, 1))(ip)\n",
        "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = squeeze_excite_block(y)\n",
        "\n",
        "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = squeeze_excite_block(y)\n",
        "\n",
        "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "\n",
        "    y = GlobalAveragePooling1D()(y)\n",
        "\n",
        "    x = concatenate([x, y])\n",
        "\n",
        "    out = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs, out)\n",
        "    # model.summary()\n",
        "\n",
        "    # add load model code here to fine-tune\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RIzwrDX1ZqQ5"
      },
      "outputs": [],
      "source": [
        "model = build_model((137, 15), 32, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fDzieLQ7Z2iG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eec25c96-d995-439b-a7ca-a93a8d6a97a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(32, 137, 15)]              0         []                            \n",
            "                                                                                                  \n",
            " permute_1 (Permute)         (32, 15, 137)                0         ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " permute_2 (Permute)         (32, 137, 15)                0         ['permute_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (32, 137, 128)               15488     ['permute_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (32, 137, 128)               512       ['conv1d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (32, 137, 128)               0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (32, 128)                    0         ['activation[0][0]']          \n",
            " GlobalAveragePooling1D)                                                                          \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (32, 1, 128)                 0         ['global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (32, 1, 8)                   1024      ['reshape[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (32, 1, 128)                 1024      ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)         (32, 137, 128)               0         ['activation[0][0]',          \n",
            "                                                                     'dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (32, 137, 256)               164096    ['multiply[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (32, 137, 256)               1024      ['conv1d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (32, 137, 256)               0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1  (32, 256)                    0         ['activation_1[0][0]']        \n",
            "  (GlobalAveragePooling1D)                                                                        \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)         (32, 1, 256)                 0         ['global_average_pooling1d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (32, 1, 16)                  4096      ['reshape_1[0][0]']           \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (32, 1, 256)                 4096      ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)       (32, 137, 256)               0         ['activation_1[0][0]',        \n",
            "                                                                     'dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (32, 137, 128)               98432     ['multiply_1[0][0]']          \n",
            "                                                                                                  \n",
            " masking (Masking)           (32, 15, 137)                0         ['permute_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (32, 137, 128)               512       ['conv1d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (32, 8)                      4672      ['masking[0][0]']             \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (32, 137, 128)               0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (32, 8)                      0         ['lstm[0][0]']                \n",
            "                                                                                                  \n",
            " global_average_pooling1d_2  (32, 128)                    0         ['activation_2[0][0]']        \n",
            "  (GlobalAveragePooling1D)                                                                        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (32, 136)                    0         ['dropout[0][0]',             \n",
            "                                                                     'global_average_pooling1d_2[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (32, 5)                      685       ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 295661 (1.13 MB)\n",
            "Trainable params: 294637 (1.12 MB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fMsvWtyqc2Ka"
      },
      "outputs": [],
      "source": [
        "f = np.load(\"mfcc.npz\")\n",
        "X, Y = f['X'], f['Y']\n",
        "x_train =  np.concatenate((X[0:200], X[300:1000]))\n",
        "y_train =  np.concatenate((Y[0:200], Y[300:1000]))\n",
        "\n",
        "\n",
        "x_test, y_test = X[200:300], Y[200:300]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H7eopHkwuRTI"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train[0:800], y_train[0:800]))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=800, reshuffle_each_iteration=True).batch(128, drop_remainder=True)\n",
        "x_val = x_train[800:]\n",
        "y_val = y_train[800:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hux34tg9oNo5"
      },
      "outputs": [],
      "source": [
        "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# model.fit(x_train, y_train, epochs=1000, batch_size=32, validation_data=(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blAtsKjqtswc",
        "outputId": "b6dbff21-af8b-4d6d-99da-ee5332b71705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 1099/2000 [04:35<03:31,  4.26it/s]"
          ]
        }
      ],
      "source": [
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def training_step(x, y):\n",
        "\n",
        "    with tf.GradientTape() as model_tape:\n",
        "        logits = model(x, training=True)\n",
        "        loss = loss_fn(y, logits)\n",
        "    grads = model_tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    acc_metric.update_state(y, logits)\n",
        "    acc = acc_metric.result()\n",
        "    acc_metric.reset_states()\n",
        "\n",
        "    return loss, acc\n",
        "\n",
        "log = {\"training_loss\":[], \"training_acc\":[],\n",
        "        \"val_loss\":[], \"val_acc\":[], \"test_acc\":[], \"test_logits\":[]}\n",
        "log_path = \"log\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \".npy\"\n",
        "\n",
        "for epoch in tqdm(range(2000)):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    for step, (x, y) in enumerate(train_dataset):\n",
        "        batch_loss, batch_acc = training_step(x, y)\n",
        "        epoch_loss += float(batch_loss)\n",
        "        epoch_acc += float(batch_acc)\n",
        "    epoch_loss /= step+1\n",
        "    epoch_acc /= step+1\n",
        "\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    val_logits = model(x_val, training=False)\n",
        "    val_loss = loss_fn(y_val, val_logits)\n",
        "    acc_metric.update_state(y_val, val_logits)\n",
        "    val_acc = acc_metric.result().numpy()\n",
        "    acc_metric.reset_states()\n",
        "\n",
        "    # print(\"Validation loss: %.4f\" % (float(val_loss)))\n",
        "    # print(\"Validation acc: %.4f\" % (float(val_acc)))\n",
        "\n",
        "    test_logits = model(x_test, training=False)\n",
        "    acc_metric.update_state(y_test, test_logits)\n",
        "    test_acc = acc_metric.result().numpy()\n",
        "    acc_metric.reset_states()\n",
        "\n",
        "    log[\"training_loss\"].append(epoch_loss)\n",
        "    log[\"training_acc\"].append(epoch_acc)\n",
        "    log[\"val_loss\"].append(val_loss)\n",
        "    log[\"val_acc\"].append(val_acc)\n",
        "    log[\"test_acc\"].append(test_acc)\n",
        "    log[\"test_logits\"].append(test_logits)\n",
        "\n",
        "\n",
        "    np.save(log_path, [log])\n",
        "\n",
        "log['test_acc'] = np.array(log['test_acc'])\n",
        "log['val_loss'] = np.array(log['val_loss'])\n",
        "testing_metric = 0\n",
        "if len(log['test_acc'][np.where(log['val_loss']-min(log['val_loss'])<1e-6)]) != 0:\n",
        "    testing_metric = log['test_acc'][np.where((max(log['val_acc']-log['val_loss']) - (log['val_acc']-log['val_loss']))<1e-6)][0]\n",
        "print(testing_metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6VJ0FrpDMwN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}